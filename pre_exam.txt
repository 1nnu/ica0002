Sun Dec 15 11:14:04 EET 2024
+ hostname
Head-Eyes
+ ansible-playbook infra.yaml --diff
[WARNING]: Collection community.general does not support Ansible version 2.10.8

PLAY [Initial setup] ***********************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-3]
ok: [1nnu-2]
ok: [1nnu-1]

TASK [init : Update APT cache] *************************************************
ok: [1nnu-3]
ok: [1nnu-2]
changed: [1nnu-1]

TASK [init : Install prometehus-node-exporter from APT] ************************
The following additional packages will be installed:
  libio-pty-perl libipc-run-perl libtime-duration-perl libtimedate-perl
  moreutils prometheus-node-exporter-collectors smartmontools
Suggested packages:
  gsmartcontrol smart-notifier mailx | mailutils
The following NEW packages will be installed:
  libio-pty-perl libipc-run-perl libtime-duration-perl libtimedate-perl
  moreutils prometheus-node-exporter prometheus-node-exporter-collectors
  smartmontools
0 upgraded, 8 newly installed, 0 to remove and 132 not upgraded.
changed: [1nnu-1]
The following additional packages will be installed:
  libio-pty-perl libipc-run-perl libtime-duration-perl libtimedate-perl
  moreutils prometheus-node-exporter-collectors smartmontools
Suggested packages:
  gsmartcontrol smart-notifier mailx | mailutils
The following NEW packages will be installed:
  libio-pty-perl libipc-run-perl libtime-duration-perl libtimedate-perl
  moreutils prometheus-node-exporter prometheus-node-exporter-collectors
  smartmontools
0 upgraded, 8 newly installed, 0 to remove and 132 not upgraded.
changed: [1nnu-3]
The following additional packages will be installed:
  libio-pty-perl libipc-run-perl libtime-duration-perl libtimedate-perl
  moreutils prometheus-node-exporter-collectors smartmontools
Suggested packages:
  gsmartcontrol smart-notifier mailx | mailutils
The following NEW packages will be installed:
  libio-pty-perl libipc-run-perl libtime-duration-perl libtimedate-perl
  moreutils prometheus-node-exporter prometheus-node-exporter-collectors
  smartmontools
0 upgraded, 8 newly installed, 0 to remove and 132 not upgraded.
changed: [1nnu-2]

TASK [init : ansible.builtin.service] ******************************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [init : Install rsyslog] **************************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [init : Start and enable rsyslog] *****************************************
ok: [1nnu-2]
ok: [1nnu-3]
ok: [1nnu-1]

TASK [init : Copy rsyslog config] **********************************************
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpkk_lf9at/50-telegraf.conf.j2
@@ -0,0 +1,6 @@
+$ActionQueueType LinkedList # use asynchronous processing
+$ActionQueueFileName srvrfwd # set file name, also enables disk mode
+$ActionResumeRetryCount -1 # infinite retries on insert failure
+$ActionQueueSaveOnShutdown on # save in-memory data if rsyslog shuts down
+
+*.* @1nnu-3:6514;RSYSLOG_SyslogProtocol23Format

changed: [1nnu-1]
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpppovmylb/50-telegraf.conf.j2
@@ -0,0 +1,6 @@
+$ActionQueueType LinkedList # use asynchronous processing
+$ActionQueueFileName srvrfwd # set file name, also enables disk mode
+$ActionResumeRetryCount -1 # infinite retries on insert failure
+$ActionQueueSaveOnShutdown on # save in-memory data if rsyslog shuts down
+
+*.* @1nnu-3:6514;RSYSLOG_SyslogProtocol23Format

changed: [1nnu-2]
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpqjs31ptv/50-telegraf.conf.j2
@@ -0,0 +1,6 @@
+$ActionQueueType LinkedList # use asynchronous processing
+$ActionQueueFileName srvrfwd # set file name, also enables disk mode
+$ActionResumeRetryCount -1 # infinite retries on insert failure
+$ActionQueueSaveOnShutdown on # save in-memory data if rsyslog shuts down
+
+*.* @1nnu-3:6514;RSYSLOG_SyslogProtocol23Format

changed: [1nnu-3]

TASK [init : Create backup user with RSA key] **********************************
changed: [1nnu-3]
changed: [1nnu-2]
changed: [1nnu-1]

TASK [init : Add backup server public key to known hosts] **********************
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpvcqx82w0/known_hosts.j2
@@ -0,0 +1,3 @@
+"{'backup': '192.168.42.132'}[0]" ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEu6pFFWyuRrl4WGFPQGElYN9txwTGm2wSntcpVAaN90
+backup ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEu6pFFWyuRrl4WGFPQGElYN9txwTGm2wSntcpVAaN90
+backup.pingix.ttu ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEu6pFFWyuRrl4WGFPQGElYN9txwTGm2wSntcpVAaN90

changed: [1nnu-1]
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpo81mdbg7/known_hosts.j2
@@ -0,0 +1,3 @@
+"{'backup': '192.168.42.132'}[0]" ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEu6pFFWyuRrl4WGFPQGElYN9txwTGm2wSntcpVAaN90
+backup ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEu6pFFWyuRrl4WGFPQGElYN9txwTGm2wSntcpVAaN90
+backup.pingix.ttu ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEu6pFFWyuRrl4WGFPQGElYN9txwTGm2wSntcpVAaN90

changed: [1nnu-3]
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpbmcni_9x/known_hosts.j2
@@ -0,0 +1,3 @@
+"{'backup': '192.168.42.132'}[0]" ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEu6pFFWyuRrl4WGFPQGElYN9txwTGm2wSntcpVAaN90
+backup ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEu6pFFWyuRrl4WGFPQGElYN9txwTGm2wSntcpVAaN90
+backup.pingix.ttu ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIEu6pFFWyuRrl4WGFPQGElYN9txwTGm2wSntcpVAaN90

changed: [1nnu-2]

TASK [init : Create directory restore dir for backup] **************************
--- before
+++ after
@@ -1,6 +1,6 @@
 {
-    "group": 0,
-    "owner": 0,
+    "group": 34,
+    "owner": 34,
     "path": "/home/backup/restore",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-3]
--- before
+++ after
@@ -1,6 +1,6 @@
 {
-    "group": 0,
-    "owner": 0,
+    "group": 34,
+    "owner": 34,
     "path": "/home/backup/restore",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-2]
--- before
+++ after
@@ -1,6 +1,6 @@
 {
-    "group": 0,
-    "owner": 0,
+    "group": 34,
+    "owner": 34,
     "path": "/home/backup/restore",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-1]

TASK [init : Install duplicity] ************************************************
The following additional packages will be installed:
  librsync2 python3-fasteners python3-future python3-lockfile
  python3-monotonic python3-nacl python3-paramiko
Suggested packages:
  python3-boto ncftp lftp tahoe-lafs python3-swiftclient python3-pip par2
  python-future-doc python-lockfile-doc python-nacl-doc python3-gssapi
  python3-invoke
The following NEW packages will be installed:
  duplicity librsync2 python3-fasteners python3-future python3-lockfile
  python3-monotonic python3-nacl python3-paramiko
0 upgraded, 8 newly installed, 0 to remove and 132 not upgraded.
changed: [1nnu-3]
The following additional packages will be installed:
  librsync2 python3-fasteners python3-future python3-lockfile
  python3-monotonic python3-nacl python3-paramiko
Suggested packages:
  python3-boto ncftp lftp tahoe-lafs python3-swiftclient python3-pip par2
  python-future-doc python-lockfile-doc python-nacl-doc python3-gssapi
  python3-invoke
The following NEW packages will be installed:
  duplicity librsync2 python3-fasteners python3-future python3-lockfile
  python3-monotonic python3-nacl python3-paramiko
0 upgraded, 8 newly installed, 0 to remove and 132 not upgraded.
changed: [1nnu-1]
The following additional packages will be installed:
  librsync2 python3-fasteners python3-future python3-lockfile
  python3-monotonic python3-nacl python3-paramiko
Suggested packages:
  python3-boto ncftp lftp tahoe-lafs python3-swiftclient python3-pip par2
  python-future-doc python-lockfile-doc python-nacl-doc python3-gssapi
  python3-invoke
The following NEW packages will be installed:
  duplicity librsync2 python3-fasteners python3-future python3-lockfile
  python3-monotonic python3-nacl python3-paramiko
0 upgraded, 8 newly installed, 0 to remove and 132 not upgraded.
changed: [1nnu-2]

RUNNING HANDLER [init : restart rsyslog] ***************************************
changed: [1nnu-2]
changed: [1nnu-3]
changed: [1nnu-1]

PLAY [Dns server] **************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [bind : Install Bind9] ****************************************************
The following additional packages will be installed:
  bind9-dnsutils bind9-host bind9-libs bind9-utils dns-root-data
Suggested packages:
  bind-doc resolvconf
The following NEW packages will be installed:
  bind9 bind9-utils dns-root-data
The following packages will be upgraded:
  bind9-dnsutils bind9-host bind9-libs
3 upgraded, 3 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]
The following additional packages will be installed:
  bind9-dnsutils bind9-host bind9-libs bind9-utils dns-root-data
Suggested packages:
  bind-doc resolvconf
The following NEW packages will be installed:
  bind9 bind9-utils dns-root-data
The following packages will be upgraded:
  bind9-dnsutils bind9-host bind9-libs
3 upgraded, 3 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-3]
The following additional packages will be installed:
  bind9-dnsutils bind9-host bind9-libs bind9-utils dns-root-data
Suggested packages:
  bind-doc resolvconf
The following NEW packages will be installed:
  bind9 bind9-utils dns-root-data
The following packages will be upgraded:
  bind9-dnsutils bind9-host bind9-libs
3 upgraded, 3 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]

TASK [bind : Install dnspython] ************************************************
The following additional packages will be installed:
  python3-requests-toolbelt
Suggested packages:
  python3-sniffio python3-trio
The following NEW packages will be installed:
  python3-dnspython python3-requests-toolbelt
0 upgraded, 2 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]
The following additional packages will be installed:
  python3-requests-toolbelt
Suggested packages:
  python3-sniffio python3-trio
The following NEW packages will be installed:
  python3-dnspython python3-requests-toolbelt
0 upgraded, 2 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-3]
The following additional packages will be installed:
  python3-requests-toolbelt
Suggested packages:
  python3-sniffio python3-trio
The following NEW packages will be installed:
  python3-dnspython python3-requests-toolbelt
0 upgraded, 2 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]

TASK [bind : Copy bind config] *************************************************
changed: [1nnu-3] => (item=None)
changed: [1nnu-1] => (item=None)
changed: [1nnu-2] => (item=None)
changed: [1nnu-3] => (item=None)
changed: [1nnu-3]
changed: [1nnu-1] => (item=None)
changed: [1nnu-1]
changed: [1nnu-2] => (item=None)
changed: [1nnu-2]

TASK [bind : Copy master zone] *************************************************
changed: [1nnu-2] => (item=None)
changed: [1nnu-1] => (item=None)
changed: [1nnu-3] => (item=None)
changed: [1nnu-2] => (item=None)
changed: [1nnu-1] => (item=None)
changed: [1nnu-2]
changed: [1nnu-1]
changed: [1nnu-3] => (item=None)
changed: [1nnu-3]

RUNNING HANDLER [bind : Restart bind] ******************************************
changed: [1nnu-2]
changed: [1nnu-3]
changed: [1nnu-1]

RUNNING HANDLER [bind : Update bind db] ****************************************
changed: [1nnu-1]
changed: [1nnu-3]
changed: [1nnu-2]

TASK [bind : Unarchive bind exporter] ******************************************
changed: [1nnu-3]
changed: [1nnu-1]
changed: [1nnu-2]

TASK [bind : link file] ********************************************************
--- before
+++ after
@@ -1,4 +1,4 @@
 {
     "path": "/usr/local/bin/prometheus-bind-exporter",
-    "state": "absent"
+    "state": "link"
 }

changed: [1nnu-2]
--- before
+++ after
@@ -1,4 +1,4 @@
 {
     "path": "/usr/local/bin/prometheus-bind-exporter",
-    "state": "absent"
+    "state": "link"
 }

changed: [1nnu-3]
--- before
+++ after
@@ -1,4 +1,4 @@
 {
     "path": "/usr/local/bin/prometheus-bind-exporter",
-    "state": "absent"
+    "state": "link"
 }

changed: [1nnu-1]

TASK [bind : Copy bind exporter service definition] ****************************
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmploei55ht/prometheus-bind-exporter.service.j2
@@ -0,0 +1,12 @@
+[Unit]
+Description=prometheus exporter for bind
+Documentation=https://github.com/digital_ocean/bind_exporter
+
+[Service]
+Restart=on-failure
+User=prometheus
+ExecStart=/usr/local/bin/prometheus-bind-exporter
+
+[Install]
+WantedBy=multi-user.target
+

changed: [1nnu-3]
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmp_brkuy4e/prometheus-bind-exporter.service.j2
@@ -0,0 +1,12 @@
+[Unit]
+Description=prometheus exporter for bind
+Documentation=https://github.com/digital_ocean/bind_exporter
+
+[Service]
+Restart=on-failure
+User=prometheus
+ExecStart=/usr/local/bin/prometheus-bind-exporter
+
+[Install]
+WantedBy=multi-user.target
+

changed: [1nnu-2]
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpt7zbq55v/prometheus-bind-exporter.service.j2
@@ -0,0 +1,12 @@
+[Unit]
+Description=prometheus exporter for bind
+Documentation=https://github.com/digital_ocean/bind_exporter
+
+[Service]
+Restart=on-failure
+User=prometheus
+ExecStart=/usr/local/bin/prometheus-bind-exporter
+
+[Install]
+WantedBy=multi-user.target
+

changed: [1nnu-1]

TASK [bind : Reload systemd] ***************************************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [bind : bind service] *****************************************************
ok: [1nnu-2] => (item=bind9)
ok: [1nnu-3] => (item=bind9)
ok: [1nnu-1] => (item=bind9)
changed: [1nnu-2] => (item=prometheus-bind-exporter)
changed: [1nnu-3] => (item=prometheus-bind-exporter)
changed: [1nnu-1] => (item=prometheus-bind-exporter)

TASK [bind : Add backup server A records] **************************************
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1]
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2]
changed: [1nnu-3] => (item=None)
changed: [1nnu-3]

TASK [bind : Add backup server CNAME records] **********************************
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1]
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2]
changed: [1nnu-3] => (item=None)
changed: [1nnu-3] => (item=None)
changed: [1nnu-3] => (item=None)
changed: [1nnu-3]

RUNNING HANDLER [bind : Restart bind] ******************************************
changed: [1nnu-3]

PLAY [Resolv] ******************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-3]
ok: [1nnu-1]
ok: [1nnu-2]

TASK [resolv : Disable systemd-resolved] ***************************************
changed: [1nnu-1]
changed: [1nnu-3]
changed: [1nnu-2]

TASK [resolv : Copy /etc/resolv.conf to hosts] *********************************
--- before: /etc/resolv.conf
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpz03ewmgv/resolv.conf.j2
@@ -1,23 +1,3 @@
-# This is /run/systemd/resolve/stub-resolv.conf managed by man:systemd-resolved(8).
-# Do not edit.
-#
-# This file might be symlinked as /etc/resolv.conf. If you're looking at
-# /etc/resolv.conf and seeing this text, you have followed the symlink.
-#
-# This is a dynamic resolv.conf file for connecting local clients to the
-# internal DNS stub resolver of systemd-resolved. This file lists all
-# configured search domains.
-#
-# Run "resolvectl status" to see details about the uplink DNS servers
-# currently in use.
-#
-# Third party programs should typically not access this file directly, but only
-# through the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a
-# different way, replace this symlink by a static file or a different symlink.
-#
-# See man:systemd-resolved.service(8) for details about the supported modes of
-# operation for /etc/resolv.conf.
-
-nameserver 127.0.0.53
-options edns0 trust-ad
-search openstacklocal
+nameserver 192.168.42.43
+nameserver 192.168.42.138
+search pingix.ttu

changed: [1nnu-3]
--- before: /etc/resolv.conf
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmp0y56ar3p/resolv.conf.j2
@@ -1,23 +1,3 @@
-# This is /run/systemd/resolve/stub-resolv.conf managed by man:systemd-resolved(8).
-# Do not edit.
-#
-# This file might be symlinked as /etc/resolv.conf. If you're looking at
-# /etc/resolv.conf and seeing this text, you have followed the symlink.
-#
-# This is a dynamic resolv.conf file for connecting local clients to the
-# internal DNS stub resolver of systemd-resolved. This file lists all
-# configured search domains.
-#
-# Run "resolvectl status" to see details about the uplink DNS servers
-# currently in use.
-#
-# Third party programs should typically not access this file directly, but only
-# through the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a
-# different way, replace this symlink by a static file or a different symlink.
-#
-# See man:systemd-resolved.service(8) for details about the supported modes of
-# operation for /etc/resolv.conf.
-
-nameserver 127.0.0.53
-options edns0 trust-ad
-search openstacklocal
+nameserver 192.168.42.43
+nameserver 192.168.42.138
+search pingix.ttu

changed: [1nnu-1]
--- before: /etc/resolv.conf
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmp1qbqvikg/resolv.conf.j2
@@ -1,23 +1,3 @@
-# This is /run/systemd/resolve/stub-resolv.conf managed by man:systemd-resolved(8).
-# Do not edit.
-#
-# This file might be symlinked as /etc/resolv.conf. If you're looking at
-# /etc/resolv.conf and seeing this text, you have followed the symlink.
-#
-# This is a dynamic resolv.conf file for connecting local clients to the
-# internal DNS stub resolver of systemd-resolved. This file lists all
-# configured search domains.
-#
-# Run "resolvectl status" to see details about the uplink DNS servers
-# currently in use.
-#
-# Third party programs should typically not access this file directly, but only
-# through the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a
-# different way, replace this symlink by a static file or a different symlink.
-#
-# See man:systemd-resolved.service(8) for details about the supported modes of
-# operation for /etc/resolv.conf.
-
-nameserver 127.0.0.53
-options edns0 trust-ad
-search openstacklocal
+nameserver 192.168.42.43
+nameserver 192.168.42.138
+search pingix.ttu

changed: [1nnu-2]

PLAY [Docker] ******************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [docker : Install Docker] *************************************************
The following additional packages will be installed:
  bridge-utils containerd dnsmasq-base pigz runc ubuntu-fan
Suggested packages:
  ifupdown aufs-tools cgroupfs-mount | cgroup-lite debootstrap docker-doc
  rinse zfs-fuse | zfsutils
The following NEW packages will be installed:
  bridge-utils containerd dnsmasq-base docker.io pigz runc ubuntu-fan
0 upgraded, 7 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]
The following additional packages will be installed:
  bridge-utils containerd dnsmasq-base pigz runc ubuntu-fan
Suggested packages:
  ifupdown aufs-tools cgroupfs-mount | cgroup-lite debootstrap docker-doc
  rinse zfs-fuse | zfsutils
The following NEW packages will be installed:
  bridge-utils containerd dnsmasq-base docker.io pigz runc ubuntu-fan
0 upgraded, 7 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-3]
The following additional packages will be installed:
  bridge-utils containerd dnsmasq-base pigz runc ubuntu-fan
Suggested packages:
  ifupdown aufs-tools cgroupfs-mount | cgroup-lite debootstrap docker-doc
  rinse zfs-fuse | zfsutils
The following NEW packages will be installed:
  bridge-utils containerd dnsmasq-base docker.io pigz runc ubuntu-fan
0 upgraded, 7 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]

TASK [docker : Check docker enabled] *******************************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [docker : Install python3-docker] *****************************************
The following additional packages will be installed:
  python3-websocket
The following NEW packages will be installed:
  python3-docker python3-websocket
0 upgraded, 2 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]
The following additional packages will be installed:
  python3-websocket
The following NEW packages will be installed:
  python3-docker python3-websocket
0 upgraded, 2 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]
The following additional packages will be installed:
  python3-websocket
The following NEW packages will be installed:
  python3-docker python3-websocket
0 upgraded, 2 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-3]

PLAY [Prometheus + grafana] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-3]

TASK [prometheus : Install prometheus] *****************************************
The following additional packages will be installed:
  fonts-glyphicons-halflings javascript-common libjs-bootstrap
  libjs-bootstrap4 libjs-d3 libjs-eonasdan-bootstrap-datetimepicker
  libjs-jquery libjs-jquery-hotkeys libjs-moment libjs-moment-timezone
  libjs-mustache libjs-popper.js libjs-rickshaw libjs-sizzle node-jquery
Suggested packages:
  apache2 | lighttpd | httpd
The following NEW packages will be installed:
  fonts-glyphicons-halflings javascript-common libjs-bootstrap
  libjs-bootstrap4 libjs-d3 libjs-eonasdan-bootstrap-datetimepicker
  libjs-jquery libjs-jquery-hotkeys libjs-moment libjs-moment-timezone
  libjs-mustache libjs-popper.js libjs-rickshaw libjs-sizzle node-jquery
  prometheus
0 upgraded, 16 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-3]

TASK [prometheus : Put prometheus args] ****************************************
--- before: /etc/default/prometheus
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpchdwh5el/default.prometheus.j2
@@ -1,110 +1 @@
-# Set the command-line arguments to pass to the server.
-# Due to shell escaping, to pass backslashes for regexes, you need to double
-# them (\\d for \d). If running under systemd, you need to double them again
-# (\\\\d to mean \d), and escape newlines too.
-ARGS=""
-
-# prometheus supports the following options:
-#
-#  --alertmanager.notification-queue-capacity=10000
-#    The capacity of the queue for pending Alertmanager notifications.
-#  --config.file="/etc/prometheus/prometheus.yml"
-#    Prometheus configuration file path.
-#  --enable-feature=<feature,...>
-#    Comma separated feature names to enable. Valid options:
-#    exemplar-storage, expand-external-labels, memory-snapshot-on-shutdown,
-#    promql-at-modifier, promql-negative-offset, remote-write-receiver,
-#    extra-scrape-metrics, new-service-discovery-manager. See
-#    https://prometheus.io/docs/prometheus/latest/feature_flags/ for more
-#    details.
-#  --log.format=logfmt
-#    Output format of log messages. One of: [logfmt, json].
-#  --log.level=info
-#    Only log messages with the given severity or above. One of: [debug, info,
-#    warn, error].
-#  --query.lookback-delta=5m
-#    The maximum lookback duration for retrieving metrics during expression
-#    evaluations and federation.
-#  --query.max-concurrency=20
-#    Maximum number of queries executed concurrently.
-#  --query.max-samples=50000000
-#    Maximum number of samples a single query can load into memory. Note that
-#    queries will fail if they try to load more samples than this into memory,
-#    so this also limits the number of samples a query can return.
-#  --query.timeout=2m
-#    Maximum time a query may take before being aborted.
-#  --rules.alert.for-grace-period=10m
-#    Minimum duration between alert and restored "for" state. This is
-#    maintained only for alerts with configured "for" time greater than grace
-#    period.
-#  --rules.alert.for-outage-tolerance=1h
-#    Max time to tolerate prometheus outage for restoring "for" state of alert.
-#  --rules.alert.resend-delay=1m
-#    Minimum amount of time to wait before resending an alert to Alertmanager.
-#  --storage.remote.flush-deadline=<duration>
-#    How long to wait flushing sample on shutdown or config reload.
-#  --storage.remote.read-concurrent-limit=10
-#    Maximum number of concurrent remote read calls. 0 means no limit.
-#  --storage.remote.read-max-bytes-in-frame=1048576
-#    Maximum number of bytes in a single frame for streaming remote read
-#    response types before marshalling. Note that client might have limit on
-#    frame size as well. 1MB as recommended by protobuf by default.
-#  --storage.remote.read-sample-limit=5e7
-#    Maximum overall number of samples to return via the remote read interface,
-#    in a single query. 0 means no limit. This limit is ignored for streamed
-#    response types.
-#  --storage.tsdb.allow-overlapping-blocks
-#    Allow overlapping blocks, which in turn enables vertical compaction and
-#    vertical query merge.
-#  --storage.tsdb.path="/var/lib/prometheus/metrics2/"
-#    Base path for metrics storage.
-#  --storage.tsdb.retention.size=STORAGE.TSDB.RETENTION.SIZE
-#    Maximum number of bytes that can be stored for blocks. A unit is required,
-#    supported units: B, KB, MB, GB, TB, PB, EB. Ex: "512MB".
-#  --storage.tsdb.retention.time=STORAGE.TSDB.RETENTION.TIME
-#    How long to retain samples in storage. When this flag is set it overrides
-#    "storage.tsdb.retention". If neither this flag nor
-#    "storage.tsdb.retention" nor "storage.tsdb.retention.size" is set, the
-#    retention time defaults to 15d. Units Supported: y, w, d, h, m, s, ms.
-#  --storage.tsdb.retention=STORAGE.TSDB.RETENTION
-#    [DEPRECATED] How long to retain samples in storage. This flag has been
-#    deprecated, use "storage.tsdb.retention.time" instead.
-#  --storage.tsdb.use-lockfile
-#    Create a lockfile in data directory.
-#  --web.config.file=""
-#    [EXPERIMENTAL] Path to configuration file that can enable TLS or
-#    authentication.
-#  --web.console.libraries="/etc/prometheus/console_libraries"
-#    Path to the console library directory.
-#  --web.console.templates="/etc/prometheus/consoles"
-#    Path to the console template directory, available at /consoles.
-#  --web.cors.origin=".*"
-#    Regex for CORS origin. It is fully anchored. Example:
-#    'https?://(domain1|domain2)\.com'.
-#  --web.enable-admin-api
-#    Enable API endpoints for admin control actions.
-#  --web.enable-lifecycle
-#    Enable shutdown and reload via HTTP request.
-#  --web.external-url=<URL>
-#    The URL under which Prometheus is externally reachable (for example, if
-#    Prometheus is served via a reverse proxy). Used for generating relative
-#    and absolute links back to Prometheus itself. If the URL has a path
-#    portion, it will be used to prefix all HTTP endpoints served by
-#    Prometheus. If omitted, relevant URL components will be derived
-#    automatically.
-#  --web.listen-address="0.0.0.0:9090"
-#    Address to listen on for UI, API, and telemetry.
-#  --web.local-assets="/usr/share/prometheus/web/"
-#    Path to static asset/templates directory.
-#  --web.max-connections=512
-#    Maximum number of simultaneous connections.
-#  --web.page-title="Prometheus Time Series Collection and Processing Server"
-#    Document title of Prometheus instance.
-#  --web.read-timeout=5m
-#    Maximum duration before timing out read of the request, and closing idle
-#    connections.
-#  --web.route-prefix=<path>
-#    Prefix for the internal routes of web endpoints. Defaults to path of
-#    --web.external-url.
-#  --web.user-assets=<path>
-#    Path to user asset directory, available at /user.
+ARGS="--web.external-url=http://"193.40.156.67"/prometheus"

changed: [1nnu-3]

TASK [prometheus : Configure prometheus] ***************************************
--- before: /etc/prometheus/prometheus.yml
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpb7bh5shx/prometheus.yml.j2
@@ -1,44 +1,58 @@
-# Sample config for Prometheus.
-
 global:
   scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
   evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
-  # scrape_timeout is set to the global default (10s).
 
-  # Attach these labels to any time series or alerts when communicating with
-  # external systems (federation, remote storage, Alertmanager).
-  external_labels:
-      monitor: 'example'
 
-# Alertmanager configuration
-alerting:
-  alertmanagers:
-  - static_configs:
-    - targets: ['localhost:9093']
-
-# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
-rule_files:
-  # - "first_rules.yml"
-  # - "second_rules.yml"
-
-# A scrape configuration containing exactly one endpoint to scrape:
-# Here it's Prometheus itself.
 scrape_configs:
-  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
   - job_name: 'prometheus'
 
-    # Override the global default and scrape targets from this job every 5 seconds.
     scrape_interval: 5s
     scrape_timeout: 5s
 
-    # metrics_path defaults to '/metrics'
+    metrics_path: '/prometheus/metrics'
     # scheme defaults to 'http'.
 
     static_configs:
       - targets: ['localhost:9090']
 
-  - job_name: node
-    # If prometheus-node-exporter is installed, grab stats about the local
-    # machine by default.
+    
+  - job_name: 'linux'
+    scrape_interval: 10s
     static_configs:
-      - targets: ['localhost:9100']
+      - targets: ['1nnu-1:9100','1nnu-2:9100','1nnu-3:9100']
+
+  - job_name: 'mysql'
+    scrape_interval: 10s
+    static_configs:
+      - targets: ['db-1:9104','db-2:9104']
+
+  - job_name: 'bind'
+    scrape_interval: 10s
+    static_configs:
+      - targets: ['ns-3:9119','ns-1:9119','ns-2:9119']
+
+  - job_name: 'nginx'
+    scrape_interval: 10s
+    static_configs:
+      - targets: ['www-1:9113','www-2:9113']
+
+  - job_name: 'influxdb'
+    scrape_interval: 10s
+    static_configs:
+      - targets: ['influxdb:9424']
+
+  - job_name: 'backup'
+    scrape_interval: 10s
+    static_configs:
+      - targets:
+          - backup.pingix.ttu:9111
+  
+  - job_name: 'keepalived'
+    scrape_interval: 10s
+    static_configs:
+      - targets: ['lb-1:9165','lb-2:9165']
+
+  - job_name: 'haproxy'
+    scrape_interval: 10s
+    static_configs:
+      - targets: ['lb-1:9101','lb-2:9101']

changed: [1nnu-3]

TASK [prometheus : ansible.builtin.service] ************************************
ok: [1nnu-3]

TASK [prometheus : Add prometheus CNAME records] *******************************
changed: [1nnu-3]

TASK [grafana : Grafana directory] *********************************************
--- before
+++ after
@@ -1,4 +1,4 @@
 {
     "path": "/opt/grafana/provisioning/dashboards",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-3] => (item=/opt/grafana/provisioning/dashboards)
--- before
+++ after
@@ -1,4 +1,4 @@
 {
     "path": "/opt/grafana/provisioning/datasources",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-3] => (item=/opt/grafana/provisioning/datasources)

TASK [grafana : Grafana configuration] *****************************************
changed: [1nnu-3]

TASK [grafana : Copy datasource.yml.j2] ****************************************
changed: [1nnu-3]

TASK [grafana : Configure dashboards] ******************************************
changed: [1nnu-3] => (item=None)
changed: [1nnu-3] => (item=None)
changed: [1nnu-3] => (item=None)
changed: [1nnu-3] => (item=None)
changed: [1nnu-3] => (item=None)
changed: [1nnu-3]

TASK [grafana : Change grafana config] *****************************************
ok: [1nnu-3]

TASK [grafana : Grafana Docker container] **************************************
--- before
+++ after
@@ -1,4 +1,4 @@
 {
-    "exists": false,
-    "running": false
+    "exists": true,
+    "running": true
 }

[DEPRECATION WARNING]: The container_default_behavior option will change its 
default value from "compatibility" to "no_defaults" in community.docker 2.0.0. 
To remove this warning, please specify an explicit value for it now. This 
feature will be removed from community.docker in version 2.0.0. Deprecation 
warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
changed: [1nnu-3]

TASK [grafana : Gather facts for the first dns_primary host] *******************
ok: [1nnu-3 -> 193.40.156.67]

TASK [grafana : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-3]

TASK [grafana : Add grafana CNAME records] *************************************
changed: [1nnu-3]

TASK [nginx : Install nginx from APT] ******************************************
The following additional packages will be installed:
  fontconfig-config fonts-dejavu-core libdeflate0 libfontconfig1 libgd3
  libjbig0 libjpeg-turbo8 libjpeg8 libnginx-mod-http-geoip2
  libnginx-mod-http-image-filter libnginx-mod-http-xslt-filter
  libnginx-mod-mail libnginx-mod-stream libnginx-mod-stream-geoip2 libtiff5
  libwebp7 libxpm4 nginx-common nginx-core
Suggested packages:
  libgd-tools fcgiwrap nginx-doc ssl-cert
The following NEW packages will be installed:
  fontconfig-config fonts-dejavu-core libdeflate0 libfontconfig1 libgd3
  libjbig0 libjpeg-turbo8 libjpeg8 libnginx-mod-http-geoip2
  libnginx-mod-http-image-filter libnginx-mod-http-xslt-filter
  libnginx-mod-mail libnginx-mod-stream libnginx-mod-stream-geoip2 libtiff5
  libwebp7 libxpm4 nginx nginx-common nginx-core prometheus-nginx-exporter
0 upgraded, 21 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-3]

TASK [nginx : nginx configuration] *********************************************
--- before: /etc/nginx/sites-enabled/default
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmplba3dg4b/default.j2
@@ -1,91 +1,24 @@
-##
-# You should look at the following URL's in order to grasp a solid understanding
-# of Nginx configuration files in order to fully unleash the power of Nginx.
-# https://www.nginx.com/resources/wiki/start/
-# https://www.nginx.com/resources/wiki/start/topics/tutorials/config_pitfalls/
-# https://wiki.debian.org/Nginx/DirectoryStructure
-#
-# In most cases, administrators will remove this file from sites-enabled/ and
-# leave it as reference inside of sites-available where it will continue to be
-# updated by the nginx packaging team.
-#
-# This file will automatically load configuration files provided by other
-# applications, such as Drupal or Wordpress. These applications will be made
-# available underneath a path with that package name, such as /drupal8.
-#
-# Please see /usr/share/doc/nginx-doc/examples/ for more detailed examples.
-##
-
-# Default server configuration
-#
 server {
-	listen 80 default_server;
-	listen [::]:80 default_server;
-
-	# SSL configuration
-	#
-	# listen 443 ssl default_server;
-	# listen [::]:443 ssl default_server;
-	#
-	# Note: You should disable gzip for SSL traffic.
-	# See: https://bugs.debian.org/773332
-	#
-	# Read up on ssl_ciphers to ensure a secure configuration.
-	# See: https://bugs.debian.org/765782
-	#
-	# Self signed certs generated by the ssl-cert package
-	# Don't use them in a production server!
-	#
-	# include snippets/snakeoil.conf;
-
-	root /var/www/html;
-
-	# Add index.php to the list if you are using PHP
-	index index.html index.htm index.nginx-debian.html;
-
-	server_name _;
-
-	location / {
-		# First attempt to serve request as file, then
-		# as directory, then fall back to displaying a 404.
-		try_files $uri $uri/ =404;
+    listen 80 default_server;
+    server_name _;
+	
+	
+    
+	location /prometheus {
+		proxy_pass http://localhost:9090;
 	}
-
-	# pass PHP scripts to FastCGI server
-	#
-	#location ~ \.php$ {
-	#	include snippets/fastcgi-php.conf;
-	#
-	#	# With php-fpm (or other unix sockets):
-	#	fastcgi_pass unix:/run/php/php7.4-fpm.sock;
-	#	# With php-cgi (or other tcp sockets):
-	#	fastcgi_pass 127.0.0.1:9000;
-	#}
-
-	# deny access to .htaccess files, if Apache's document root
-	# concurs with nginx's one
-	#
-	#location ~ /\.ht {
-	#	deny all;
-	#}
+	
+	location /grafana {
+		proxy_set_header Host $http_host;
+		proxy_pass http://localhost:3001;
+	}
+		
 }
 
 
-# Virtual Host configuration for example.com
-#
-# You can move that to a different file under sites-available/ and symlink that
-# to sites-enabled/ to enable it.
-#
-#server {
-#	listen 80;
-#	listen [::]:80;
-#
-#	server_name example.com;
-#
-#	root /var/www/example.com;
-#	index index.html;
-#
-#	location / {
-#		try_files $uri $uri/ =404;
-#	}
-#}
+server {
+	listen 8080 default_server;
+	location /stub_status {
+		stub_status;
+	}
+}

changed: [1nnu-3]

RUNNING HANDLER [prometheus : Restart Prometheus] ******************************
changed: [1nnu-3]

RUNNING HANDLER [grafana : Restart Grafana] ************************************
--- before
+++ after
@@ -1,4 +1,4 @@
 {
-    "restarted": false,
+    "restarted": true,
     "running": true
 }

changed: [1nnu-3]

RUNNING HANDLER [nginx : restart nginx] ****************************************
changed: [1nnu-3]

RUNNING HANDLER [nginx : restart nginx-exporter] *******************************
changed: [1nnu-3]

TASK [nginx : nginx service] ***************************************************
ok: [1nnu-3] => (item=nginx)
ok: [1nnu-3] => (item=prometheus-nginx-exporter)

PLAY [InfluxDb] ****************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-3]

TASK [influxdb : add influx gpg key] *******************************************
changed: [1nnu-3]

TASK [influxdb : add influx repo] **********************************************
--- before: /dev/null
+++ after: /etc/apt/sources.list.d/repos_influxdata_com_debian.list
@@ -0,0 +1 @@
+deb [signed-by=/etc/apt/trusted.gpg.d/influxdata-archive_compat.gpg] https://repos.influxdata.com/debian stable main

changed: [1nnu-3]

TASK [influxdb : Install influx] ***********************************************
The following NEW packages will be installed:
  influxdb
0 upgraded, 1 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-3]

TASK [influxdb : Copy influxdb config] *****************************************
--- before: /etc/influxdb/influxdb.conf
+++ after: /home/innar/ica0002/roles/influxdb/files/influxdb.conf
@@ -1,596 +1,11 @@
-### Welcome to the InfluxDB configuration file.
-
-# The values in this file override the default values used by the system if
-# a config option is not specified. The commented out lines are the configuration
-# field and the default value used. Uncommenting a line and changing the value
-# will change the value used at runtime when the process is restarted.
-
-# Once every 24 hours InfluxDB will report usage data to usage.influxdata.com
-# The data includes a random ID, os, arch, version, the number of series and other
-# usage data. No data from user databases is ever transmitted.
-# Change this option to true to disable reporting.
-# reporting-disabled = false
-
-# Bind address to use for the RPC service for backup and restore.
-# bind-address = "127.0.0.1:8088"
-
-###
-### [meta]
-###
-### Controls the parameters for the Raft consensus group that stores metadata
-### about the InfluxDB cluster.
-###
-
 [meta]
-  # Where the metadata/raft database is stored
   dir = "/var/lib/influxdb/meta"
-
-  # Automatically create a default retention policy when creating a database.
-  # retention-autocreate = true
-
-  # If log messages are printed for the meta service
-  # logging-enabled = true
-
-###
-### [data]
-###
-### Controls where the actual shard data for InfluxDB lives and how it is
-### flushed from the WAL. "dir" may need to be changed to a suitable place
-### for your system, but the WAL settings are an advanced configuration. The
-### defaults should work for most systems.
-###
-
 [data]
-  # The directory where the TSM storage engine stores TSM files.
   dir = "/var/lib/influxdb/data"
-
-  # The directory where the TSM storage engine stores WAL files.
   wal-dir = "/var/lib/influxdb/wal"
-
-  # The amount of time that a write will wait before fsyncing.  A duration
-  # greater than 0 can be used to batch up multiple fsync calls.  This is useful for slower
-  # disks or when WAL write contention is seen.  A value of 0s fsyncs every write to the WAL.
-  # Values in the range of 0-100ms are recommended for non-SSD disks.
-  # wal-fsync-delay = "0s"
-
-
-  # The type of shard index to use for new shards.  The default is an in-memory index that is
-  # recreated at startup.  A value of "tsi1" will use a disk based index that supports higher
-  # cardinality datasets.
-  # index-version = "inmem"
-
-  # Trace logging provides more verbose output around the tsm engine. Turning
-  # this on can provide more useful output for debugging tsm engine issues.
-  # trace-logging-enabled = false
-
-  # Whether queries should be logged before execution. Very useful for troubleshooting, but will
-  # log any sensitive data contained within a query.
-  # query-log-enabled = true
-
-  # Provides more error checking. For example, SELECT INTO will err out inserting an +/-Inf value
-  # rather than silently failing.
-  # strict-error-handling = false
-
-  # Validates incoming writes to ensure keys only have valid unicode characters.
-  # This setting will incur a small overhead because every key must be checked.
-  # validate-keys = false
-
-  # Settings for the TSM engine
-
-  # CacheMaxMemorySize is the maximum size a shard's cache can
-  # reach before it starts rejecting writes.
-  # Valid size suffixes are k, m, or g (case insensitive, 1024 = 1k).
-  # Values without a size suffix are in bytes.
-  # cache-max-memory-size = "1g"
-
-  # CacheSnapshotMemorySize is the size at which the engine will
-  # snapshot the cache and write it to a TSM file, freeing up memory
-  # Valid size suffixes are k, m, or g (case insensitive, 1024 = 1k).
-  # Values without a size suffix are in bytes.
-  # cache-snapshot-memory-size = "25m"
-
-  # CacheSnapshotWriteColdDuration is the length of time at
-  # which the engine will snapshot the cache and write it to
-  # a new TSM file if the shard hasn't received writes or deletes
-  # cache-snapshot-write-cold-duration = "10m"
-
-  # CompactFullWriteColdDuration is the duration at which the engine
-  # will compact all TSM files in a shard if it hasn't received a
-  # write or delete
-  # compact-full-write-cold-duration = "4h"
-
-  # The maximum number of concurrent full and level compactions that can run at one time.  A
-  # value of 0 results in 50% of runtime.GOMAXPROCS(0) used at runtime.  Any number greater
-  # than 0 limits compactions to that value.  This setting does not apply
-  # to cache snapshotting.
-  # max-concurrent-compactions = 0
-
-  # CompactThroughput is the rate limit in bytes per second that we
-  # will allow TSM compactions to write to disk. Note that short bursts are allowed
-  # to happen at a possibly larger value, set by CompactThroughputBurst
-  # compact-throughput = "48m"
-
-  # CompactThroughputBurst is the rate limit in bytes per second that we
-  # will allow TSM compactions to write to disk.
-  # compact-throughput-burst = "48m"
-
-  # If true, then the mmap advise value MADV_WILLNEED will be provided to the kernel with respect to
-  # TSM files. This setting has been found to be problematic on some kernels, and defaults to off.
-  # It might help users who have slow disks in some cases.
-  # tsm-use-madv-willneed = false
-
-  # Settings for the inmem index
-
-  # The maximum series allowed per database before writes are dropped.  This limit can prevent
-  # high cardinality issues at the database level.  This limit can be disabled by setting it to
-  # 0.
-  # max-series-per-database = 1000000
-
-  # The maximum number of tag values per tag that are allowed before writes are dropped.  This limit
-  # can prevent high cardinality tag values from being written to a measurement.  This limit can be
-  # disabled by setting it to 0.
-  # max-values-per-tag = 100000
-
-  # Settings for the tsi1 index
-
-  # The threshold, in bytes, when an index write-ahead log file will compact
-  # into an index file. Lower sizes will cause log files to be compacted more
-  # quickly and result in lower heap usage at the expense of write throughput.
-  # Higher sizes will be compacted less frequently, store more series in-memory,
-  # and provide higher write throughput.
-  # Valid size suffixes are k, m, or g (case insensitive, 1024 = 1k).
-  # Values without a size suffix are in bytes.
-  # max-index-log-file-size = "1m"
-
-  # The size of the internal cache used in the TSI index to store previously 
-  # calculated series results. Cached results will be returned quickly from the cache rather
-  # than needing to be recalculated when a subsequent query with a matching tag key/value 
-  # predicate is executed. Setting this value to 0 will disable the cache, which may
-  # lead to query performance issues.
-  # This value should only be increased if it is known that the set of regularly used 
-  # tag key/value predicates across all measurements for a database is larger than 100. An
-  # increase in cache size may lead to an increase in heap usage.
   series-id-set-cache-size = 100
-
-###
-### [coordinator]
-###
-### Controls the clustering service configuration.
-###
-
-[coordinator]
-  # The default time a write request will wait until a "timeout" error is returned to the caller.
-  # write-timeout = "10s"
-
-  # The maximum number of concurrent queries allowed to be executing at one time.  If a query is
-  # executed and exceeds this limit, an error is returned to the caller.  This limit can be disabled
-  # by setting it to 0.
-  # max-concurrent-queries = 0
-
-  # The maximum time a query will is allowed to execute before being killed by the system.  This limit
-  # can help prevent run away queries.  Setting the value to 0 disables the limit.
-  # query-timeout = "0s"
-
-  # The time threshold when a query will be logged as a slow query.  This limit can be set to help
-  # discover slow or resource intensive queries.  Setting the value to 0 disables the slow query logging.
-  # log-queries-after = "0s"
-
-  # The maximum number of points a SELECT can process.  A value of 0 will make
-  # the maximum point count unlimited.  This will only be checked every second so queries will not
-  # be aborted immediately when hitting the limit.
-  # max-select-point = 0
-
-  # The maximum number of series a SELECT can run.  A value of 0 will make the maximum series
-  # count unlimited.
-  # max-select-series = 0
-
-  # The maximum number of group by time bucket a SELECT can create.  A value of zero will max the maximum
-  # number of buckets unlimited.
-  # max-select-buckets = 0
-
-###
-### [retention]
-###
-### Controls the enforcement of retention policies for evicting old data.
-###
-
-[retention]
-  # Determines whether retention policy enforcement enabled.
-  # enabled = true
-
-  # The interval of time when retention policy enforcement checks run.
-  # check-interval = "30m"
-
-###
-### [shard-precreation]
-###
-### Controls the precreation of shards, so they are available before data arrives.
-### Only shards that, after creation, will have both a start- and end-time in the
-### future, will ever be created. Shards are never precreated that would be wholly
-### or partially in the past.
-
-[shard-precreation]
-  # Determines whether shard pre-creation service is enabled.
-  # enabled = true
-
-  # The interval of time when the check to pre-create new shards runs.
-  # check-interval = "10m"
-
-  # The default period ahead of the endtime of a shard group that its successor
-  # group is created.
-  # advance-period = "30m"
-
-###
-### Controls the system self-monitoring, statistics and diagnostics.
-###
-### The internal database for monitoring data is created automatically if
-### if it does not already exist. The target retention within this database
-### is called 'monitor' and is also created with a retention period of 7 days
-### and a replication factor of 1, if it does not exist. In all cases the
-### this retention policy is configured as the default for the database.
-
-[monitor]
-  # Whether to record statistics internally.
-  # store-enabled = true
-
-  # The destination database for recorded statistics
-  # store-database = "_internal"
-
-  # The interval at which to record statistics
-  # store-interval = "10s"
-
-###
-### [http]
-###
-### Controls how the HTTP endpoints are configured. These are the primary
-### mechanism for getting data into and out of InfluxDB.
-###
-
+  query-log-enabled = false
 [http]
-  # Determines whether HTTP endpoint is enabled.
-  # enabled = true
-
-  # Determines whether the Flux query endpoint is enabled.
-  # flux-enabled = false
-
-  # Determines whether the Flux query logging is enabled.
-  # flux-log-enabled = false
-
-  # The bind address used by the HTTP service.
-  # bind-address = ":8086"
-
-  # Determines whether user authentication is enabled over HTTP/HTTPS.
-  # auth-enabled = false
-
-  # The default realm sent back when issuing a basic auth challenge.
-  # realm = "InfluxDB"
-
-  # Determines whether HTTP request logging is enabled.
-  # log-enabled = true
-
-  # Determines whether the HTTP write request logs should be suppressed when the log is enabled.
-  # suppress-write-log = false
-
-  # When HTTP request logging is enabled, this option specifies the path where
-  # log entries should be written. If unspecified, the default is to write to stderr, which
-  # intermingles HTTP logs with internal InfluxDB logging.
-  #
-  # If influxd is unable to access the specified path, it will log an error and fall back to writing
-  # the request log to stderr.
-  # access-log-path = ""
-
-  # Filters which requests should be logged. Each filter is of the pattern NNN, NNX, or NXX where N is
-  # a number and X is a wildcard for any number. To filter all 5xx responses, use the string 5xx.
-  # If multiple filters are used, then only one has to match. The default is to have no filters which
-  # will cause every request to be printed.
-  # access-log-status-filters = []
-
-  # Determines whether detailed write logging is enabled.
-  # write-tracing = false
-
-  # Determines whether the pprof endpoint is enabled.  This endpoint is used for
-  # troubleshooting and monitoring.
-  # pprof-enabled = true
-
-  # Enables authentication on pprof endpoints. Users will need admin permissions
-  # to access the pprof endpoints when this setting is enabled. This setting has
-  # no effect if either auth-enabled or pprof-enabled are set to false.
-  # pprof-auth-enabled = false
-
-  # Enables a pprof endpoint that binds to localhost:6060 immediately on startup.
-  # This is only needed to debug startup issues.
-  # debug-pprof-enabled = false
-
-  # Enables authentication on the /ping, /metrics, and deprecated /status
-  # endpoints. This setting has no effect if auth-enabled is set to false.
-  # ping-auth-enabled = false
-
-  # Determines whether HTTPS is enabled.
-  # https-enabled = false
-
-  # The SSL certificate to use when HTTPS is enabled.
-  # https-certificate = "/etc/ssl/influxdb.pem"
-
-  # Use a separate private key location.
-  # https-private-key = ""
-
-  # The JWT auth shared secret to validate requests using JSON web tokens.
-  # shared-secret = ""
-
-  # The default chunk size for result sets that should be chunked.
-  # max-row-limit = 0
-
-  # The maximum number of HTTP connections that may be open at once.  New connections that
-  # would exceed this limit are dropped.  Setting this value to 0 disables the limit.
-  # max-connection-limit = 0
-
-  # Enable http service over unix domain socket
-  # unix-socket-enabled = false
-
-  # The path of the unix domain socket.
-  # bind-socket = "/var/run/influxdb.sock"
-
-  # The maximum size of a client request body, in bytes. Setting this value to 0 disables the limit.
-  # max-body-size = 25000000
-
-  # The maximum number of writes processed concurrently.
-  # Setting this to 0 disables the limit.
-  # max-concurrent-write-limit = 0
-
-  # The maximum number of writes queued for processing.
-  # Setting this to 0 disables the limit.
-  # max-enqueued-write-limit = 0
-
-  # The maximum duration for a write to wait in the queue to be processed.
-  # Setting this to 0 or setting max-concurrent-write-limit to 0 disables the limit.
-  # enqueued-write-timeout = 0
-
-	# User supplied HTTP response headers
-	#
-	# [http.headers]
-	#   X-Header-1 = "Header Value 1"
-	#   X-Header-2 = "Header Value 2"
-
-###
-### [logging]
-###
-### Controls how the logger emits logs to the output.
-###
-
-[logging]
-  # Determines which log encoder to use for logs. Available options
-  # are auto, logfmt, and json. auto will use a more a more user-friendly
-  # output format if the output terminal is a TTY, but the format is not as
-  # easily machine-readable. When the output is a non-TTY, auto will use
-  # logfmt.
-  # format = "auto"
-
-  # Determines which level of logs will be emitted. The available levels
-  # are error, warn, info, and debug. Logs that are equal to or above the
-  # specified level will be emitted.
-  # level = "info"
-
-  # Suppresses the logo output that is printed when the program is started.
-  # The logo is always suppressed if STDOUT is not a TTY.
-  # suppress-logo = false
-
-###
-### [subscriber]
-###
-### Controls the subscriptions, which can be used to fork a copy of all data
-### received by the InfluxDB host.
-###
-
-[subscriber]
-  # Determines whether the subscriber service is enabled.
-  # enabled = true
-
-  # The default timeout for HTTP writes to subscribers.
-  # http-timeout = "30s"
-
-  # Allows insecure HTTPS connections to subscribers.  This is useful when testing with self-
-  # signed certificates.
-  # insecure-skip-verify = false
-
-  # The path to the PEM encoded CA certs file. If the empty string, the default system certs will be used
-  # ca-certs = ""
-
-  # The number of writer goroutines processing the write channel.
-  # write-concurrency = 40
-
-  # The number of in-flight writes buffered in the write channel.
-  # write-buffer-size = 1000
-
-
-###
-### [[graphite]]
-###
-### Controls one or many listeners for Graphite data.
-###
-
-[[graphite]]
-  # Determines whether the graphite endpoint is enabled.
-  # enabled = false
-  # database = "graphite"
-  # retention-policy = ""
-  # bind-address = ":2003"
-  # protocol = "tcp"
-  # consistency-level = "one"
-
-  # These next lines control how batching works. You should have this enabled
-  # otherwise you could get dropped metrics or poor performance. Batching
-  # will buffer points in memory if you have many coming in.
-
-  # Flush if this many points get buffered
-  # batch-size = 5000
-
-  # number of batches that may be pending in memory
-  # batch-pending = 10
-
-  # Flush at least this often even if we haven't hit buffer limit
-  # batch-timeout = "1s"
-
-  # UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.
-  # udp-read-buffer = 0
-
-  ### This string joins multiple matching 'measurement' values providing more control over the final measurement name.
-  # separator = "."
-
-  ### Default tags that will be added to all metrics.  These can be overridden at the template level
-  ### or by tags extracted from metric
-  # tags = ["region=us-east", "zone=1c"]
-
-  ### Each template line requires a template pattern.  It can have an optional
-  ### filter before the template and separated by spaces.  It can also have optional extra
-  ### tags following the template.  Multiple tags should be separated by commas and no spaces
-  ### similar to the line protocol format.  There can be only one default template.
-  # templates = [
-  #   "*.app env.service.resource.measurement",
-  #   # Default template
-  #   "server.*",
-  # ]
-
-###
-### [collectd]
-###
-### Controls one or many listeners for collectd data.
-###
-
-[[collectd]]
-  # enabled = false
-  # bind-address = ":25826"
-  # database = "collectd"
-  # retention-policy = ""
-  #
-  # The collectd service supports either scanning a directory for multiple types
-  # db files, or specifying a single db file.
-  # typesdb = "/usr/local/share/collectd"
-  #
-  # security-level = "none"
-  # auth-file = "/etc/collectd/auth_file"
-
-  # These next lines control how batching works. You should have this enabled
-  # otherwise you could get dropped metrics or poor performance. Batching
-  # will buffer points in memory if you have many coming in.
-
-  # Flush if this many points get buffered
-  # batch-size = 5000
-
-  # Number of batches that may be pending in memory
-  # batch-pending = 10
-
-  # Flush at least this often even if we haven't hit buffer limit
-  # batch-timeout = "10s"
-
-  # UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.
-  # read-buffer = 0
-
-  # Multi-value plugins can be handled two ways.
-  # "split" will parse and store the multi-value plugin data into separate measurements
-  # "join" will parse and store the multi-value plugin as a single multi-value measurement.
-  # "split" is the default behavior for backward compatibility with previous versions of influxdb.
-  # parse-multivalue-plugin = "split"
-###
-### [opentsdb]
-###
-### Controls one or many listeners for OpenTSDB data.
-###
-
-[[opentsdb]]
-  # enabled = false
-  # bind-address = ":4242"
-  # database = "opentsdb"
-  # retention-policy = ""
-  # consistency-level = "one"
-  # tls-enabled = false
-  # certificate= "/etc/ssl/influxdb.pem"
-
-  # Log an error for every malformed point.
-  # log-point-errors = true
-
-  # These next lines control how batching works. You should have this enabled
-  # otherwise you could get dropped metrics or poor performance. Only points
-  # metrics received over the telnet protocol undergo batching.
-
-  # Flush if this many points get buffered
-  # batch-size = 1000
-
-  # Number of batches that may be pending in memory
-  # batch-pending = 5
-
-  # Flush at least this often even if we haven't hit buffer limit
-  # batch-timeout = "1s"
-
-###
-### [[udp]]
-###
-### Controls the listeners for InfluxDB line protocol data via UDP.
-###
-
-[[udp]]
-  # enabled = false
-  # bind-address = ":8089"
-  # database = "udp"
-  # retention-policy = ""
-
-  # InfluxDB precision for timestamps on received points ("" or "n", "u", "ms", "s", "m", "h")
-  # precision = ""
-
-  # These next lines control how batching works. You should have this enabled
-  # otherwise you could get dropped metrics or poor performance. Batching
-  # will buffer points in memory if you have many coming in.
-
-  # Flush if this many points get buffered
-  # batch-size = 5000
-
-  # Number of batches that may be pending in memory
-  # batch-pending = 10
-
-  # Will flush at least this often even if we haven't hit buffer limit
-  # batch-timeout = "1s"
-
-  # UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.
-  # read-buffer = 0
-
-###
-### [continuous_queries]
-###
-### Controls how continuous queries are run within InfluxDB.
-###
-
-[continuous_queries]
-  # Determines whether the continuous query service is enabled.
-  # enabled = true
-
-  # Controls whether queries are logged when executed by the CQ service.
-  # log-enabled = true
-
-  # Controls whether queries are logged to the self-monitoring data store.
-  # query-stats-enabled = false
-
-  # interval for how often continuous queries will be checked if they need to run
-  # run-interval = "1s"
-
-###
-### [tls]
-###
-### Global configuration settings for TLS in InfluxDB.
-###
-
-[tls]
-  # Determines the available set of cipher suites. See https://golang.org/pkg/crypto/tls/#pkg-constants
-  # for a list of available ciphers, which depends on the version of Go (use the query
-  # SHOW DIAGNOSTICS to see the version of Go used to build InfluxDB). If not specified, uses
-  # the default settings from Go's crypto/tls package.
-  # ciphers = [
-  #   "TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305",
-  #   "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305",
-  # ]
-
-  # Minimum version of the tls protocol that will be negotiated. If not specified, uses the
-  # default settings from Go's crypto/tls package.
-  # min-version = "tls1.2"
-
-  # Maximum version of the tls protocol that will be negotiated. If not specified, uses the
-  # default settings from Go's crypto/tls package.
-  # max-version = "tls1.3"
+  log-enabled = false
+  write-tracing = false
+  
\ No newline at end of file

changed: [1nnu-3]

TASK [influxdb : influxdb started] *********************************************
changed: [1nnu-3]

TASK [influxdb : Install telegraf] *********************************************
The following NEW packages will be installed:
  telegraf
0 upgraded, 1 newly installed, 0 to remove and 130 not upgraded.
changed: [1nnu-3]

TASK [influxdb : Copy telegraf conf] *******************************************
diff skipped: destination file size is greater than 104448
changed: [1nnu-3]

TASK [influxdb : telegraf] *****************************************************
changed: [1nnu-3]

TASK [influxdb : Download Influxdb exporter] ***********************************
changed: [1nnu-3]

TASK [influxdb : Copy influx exporter service file] ****************************
--- before
+++ after: /home/innar/ica0002/roles/influxdb/files/influx_exporter.service
@@ -0,0 +1,9 @@
+[Unit]
+After=network-online.target
+
+[Service]
+User=prometheus
+ExecStart=/usr/local/bin/influx_stats_exporter_linux_amd64
+
+[Install]
+WantedBy=multi-user.target

changed: [1nnu-3]

TASK [influxdb : Start and enable influx exporter] *****************************
changed: [1nnu-3]

TASK [influxdb : Create directory for influxdb backup] *************************
--- before
+++ after
@@ -1,7 +1,7 @@
 {
-    "group": 0,
-    "mode": "0755",
-    "owner": 0,
+    "group": 34,
+    "mode": "0750",
+    "owner": 34,
     "path": "/home/backup/influxdb",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-3]

TASK [influxdb : Copy cron schedule file] **************************************
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmp6cm0zxcq/influxdb-backup
@@ -0,0 +1,2 @@
+18 22 * * * backup rm -rf /home/backup/influxdb/*; influxd backup -portable -db telegraf /home/backup/influxdb
+19 22 * * * backup duplicity --no-encryption full /home/backup/influxdb/ rsync://1nnu@backup//home/1nnu/influxdb

changed: [1nnu-3]

TASK [influxdb : Gather facts for the first dns_primary host] ******************
ok: [1nnu-3 -> 193.40.156.67]

TASK [influxdb : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-3]

TASK [influxdb : Add influxdb CNAME records] ***********************************
changed: [1nnu-3]

TASK [agama_client : Add agama-client as system user] **************************
changed: [1nnu-3]

TASK [agama_client : Install fping] ********************************************
The following NEW packages will be installed:
  fping
0 upgraded, 1 newly installed, 0 to remove and 130 not upgraded.
changed: [1nnu-3]

TASK [agama_client : copy script to /usr/local/bin/agama-client] ***************
--- before
+++ after: /home/innar/ica0002/roles/agama_client/files/agama-client
@@ -0,0 +1,70 @@
+#!/bin/bash -eu
+
+# Please help Dora to find problems in this script
+
+for t in database_url database_name subnet; do
+    if ! grep -q "^${t}=" /etc/agama-client/agama-client.conf; then
+        logger "$0 Failed to get $t from config"
+        exit 1
+    fi
+done
+
+which fping > /dev/null || { logger "$0 fping not found"; exit 1; }
+
+logger "Starting agama-client..."
+
+db_url=$(grep "^database_url=" /etc/agama-client/agama-client.conf | sed 's/^.*=//')
+db_name=$(grep "^database_name=" /etc/agama-client/agama-client.conf | sed 's/^.*=//')
+subnet=$(grep "^subnet=" /etc/agama-client/agama-client.conf | sed 's/^.*=//')
+
+for i in {1..30}; do
+    if $(curl -s "$db_url/ping"); then
+        logger "Will push data to $db_url"
+        break
+    else
+        logger "Failed to connect to $db_url. InfluxDB is not running? ($i)"
+        sleep 5
+    fi
+done
+
+logger "Creating database $db_name in $db_url"
+curl -i -XPOST "$db_url/query" --data-urlencode "q=CREATE DATABASE $db_name" 1>/dev/null 2>/dev/null || { logger "$0 Failed to create database"; exit 1; }
+
+while true; do
+    alive_hosts=$(fping -g $subnet -a 2>/dev/null || true)
+    logger "Discovered $(echo "$alive_hosts" | wc -l) IPs"
+    for vm_ip in $alive_hosts; do
+        # Getting content of agama page
+        content=$(curl --connect-timeout 1 -w "%{http_code}" -s $vm_ip || continue)
+        if test ${content: -3} -ne 200; then
+            # nothing to do, going to next student
+            continue
+        fi
+        # Getting where it's hosted
+        vm_name=$(echo "$content" | grep "running on" | awk '{print $5}')
+        if [ -z $vm_name ]; then
+            # No agama running, skipping
+            continue
+        fi
+        ptr=$(host -W1 $vm_ip $vm_ip | awk '/domain name pointer/ {print $5}')
+        if ! [ -z "$ptr" ]; then
+            logger "Resolved $vm_ip to $ptr"
+            vm_name="$ptr"
+        fi
+        # Number of items in agama
+        table_rows=$(echo "$content" | grep -c "</tr>")
+        # Write stats to inflixdb
+        curl -i -XPOST "${db_url}/write?db=$db_name" --data-binary "agama-stats,name=$vm_name items=$table_rows" 1>/dev/null 2>/dev/null
+        # If hostname exists in agama - delete it
+        if $(echo "$content" | grep -q $(hostname)); then
+            for delete_url in $(echo "$content" | grep $(hostname) | grep -o '/items/.*/swap-state' | sed 's/swap-state/delete/'); do
+                curl -s $vm_ip$delete_url -o /dev/null || logger "Failed to delete $(hostname) from $vm_ip"
+            done
+        fi
+        # Add new item to agama
+        curl -s -XPOST $vm_ip/items/add -F new_item="Checked from $(hostname) at $(date)" -o /dev/null || logger "Failed to update Agama on $vm_ip"
+        logger "Posted check message to $vm_ip"
+    done
+    logger "Waiting for the next cycle to start..."
+    sleep 300
+done
\ No newline at end of file

changed: [1nnu-3]

TASK [agama_client : copy service definition to /etc/systemd/system/] **********
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpyxzh4od3/agama-client.service.j2
@@ -0,0 +1,11 @@
+[Unit]
+Description=Shell script which outputs agama status
+Documentation=https://github.com/romankuchin/ica0002-2024/tree/0195f92be457a0f490c272daec0a757fb7232976/08-logging
+After=network-online.target
+
+[Service]
+User=agama-client
+ExecStart=/usr/local/bin/agama-client
+
+[Install]
+WantedBy=multi-user.target

changed: [1nnu-3]

TASK [agama_client : Reload systemd] *******************************************
ok: [1nnu-3]

TASK [agama_client : Create directory agama-client app conf dir] ***************
--- before
+++ after
@@ -1,5 +1,5 @@
 {
-    "owner": 0,
+    "owner": 1001,
     "path": "/etc/agama-client/",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-3]

TASK [agama_client : copy conf to to /etc/agama-client/] ***********************
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpzt4hdqwa/agama-client.conf.j2
@@ -0,0 +1,3 @@
+database_url=http://influxdb:8086
+database_name=agama
+subnet=192.168.42.0/23

changed: [1nnu-3]

TASK [agama_client : agama-client started] *************************************
changed: [1nnu-3]

RUNNING HANDLER [influxdb : restart telegraf] **********************************
changed: [1nnu-3]

RUNNING HANDLER [influxdb : restart cron] **************************************
changed: [1nnu-3]

RUNNING HANDLER [agama_client : restart agama-client] **************************
changed: [1nnu-3]

PLAY [Database server] *********************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Install mysql-server from APT] ***********************************
The following additional packages will be installed:
  libcgi-fast-perl libcgi-pm-perl libclone-perl libencode-locale-perl
  libevent-pthreads-2.1-7 libfcgi-bin libfcgi-perl libfcgi0ldbl
  libhtml-parser-perl libhtml-tagset-perl libhtml-template-perl
  libhttp-date-perl libhttp-message-perl libio-html-perl
  liblwp-mediatypes-perl libmecab2 libprotobuf-lite23 liburi-perl mecab-ipadic
  mecab-ipadic-utf8 mecab-utils mysql-client-8.0 mysql-client-core-8.0
  mysql-common mysql-server-8.0 mysql-server-core-8.0
Suggested packages:
  libdata-dump-perl libipc-sharedcache-perl libbusiness-isbn-perl libwww-perl
  mailx tinyca
The following NEW packages will be installed:
  libcgi-fast-perl libcgi-pm-perl libclone-perl libencode-locale-perl
  libevent-pthreads-2.1-7 libfcgi-bin libfcgi-perl libfcgi0ldbl
  libhtml-parser-perl libhtml-tagset-perl libhtml-template-perl
  libhttp-date-perl libhttp-message-perl libio-html-perl
  liblwp-mediatypes-perl libmecab2 libprotobuf-lite23 liburi-perl mecab-ipadic
  mecab-ipadic-utf8 mecab-utils mysql-client-8.0 mysql-client-core-8.0
  mysql-common mysql-server mysql-server-8.0 mysql-server-core-8.0
0 upgraded, 27 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]
The following additional packages will be installed:
  libcgi-fast-perl libcgi-pm-perl libclone-perl libencode-locale-perl
  libevent-pthreads-2.1-7 libfcgi-bin libfcgi-perl libfcgi0ldbl
  libhtml-parser-perl libhtml-tagset-perl libhtml-template-perl
  libhttp-date-perl libhttp-message-perl libio-html-perl
  liblwp-mediatypes-perl libmecab2 libprotobuf-lite23 liburi-perl mecab-ipadic
  mecab-ipadic-utf8 mecab-utils mysql-client-8.0 mysql-client-core-8.0
  mysql-common mysql-server-8.0 mysql-server-core-8.0
Suggested packages:
  libdata-dump-perl libipc-sharedcache-perl libbusiness-isbn-perl libwww-perl
  mailx tinyca
The following NEW packages will be installed:
  libcgi-fast-perl libcgi-pm-perl libclone-perl libencode-locale-perl
  libevent-pthreads-2.1-7 libfcgi-bin libfcgi-perl libfcgi0ldbl
  libhtml-parser-perl libhtml-tagset-perl libhtml-template-perl
  libhttp-date-perl libhttp-message-perl libio-html-perl
  liblwp-mediatypes-perl libmecab2 libprotobuf-lite23 liburi-perl mecab-ipadic
  mecab-ipadic-utf8 mecab-utils mysql-client-8.0 mysql-client-core-8.0
  mysql-common mysql-server mysql-server-8.0 mysql-server-core-8.0
0 upgraded, 27 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]

TASK [mysql : Mysql configuration] *********************************************
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpazwxff5d/override.cnf.j2
@@ -0,0 +1,6 @@
+[mysqld]
+bind-address = 0.0.0.0
+server-id = 43
+replicate-do-db = agama
+relay-log = /var/log/mysql/mysql-relay.log
+log-bin = /var/log/mysql/mysql-bin.log

changed: [1nnu-1]
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmp10hwizd4/override.cnf.j2
@@ -0,0 +1,6 @@
+[mysqld]
+bind-address = 0.0.0.0
+server-id = 138
+replicate-do-db = agama
+relay-log = /var/log/mysql/mysql-relay.log
+log-bin = /var/log/mysql/mysql-bin.log

changed: [1nnu-2]

TASK [mysql : Install PyMySql from APT] ****************************************
Suggested packages:
  python-pymysql-doc
The following NEW packages will be installed:
  python3-pymysql
0 upgraded, 1 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]
Suggested packages:
  python-pymysql-doc
The following NEW packages will be installed:
  python3-pymysql
0 upgraded, 1 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]

TASK [mysql : Check mysql enabled and started] *********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Create database] *************************************************
changed: [1nnu-2]
changed: [1nnu-1]

TASK [mysql : Create agama as database user] ***********************************
changed: [1nnu-2]
changed: [1nnu-1]

TASK [mysql : Install mysql exporter] ******************************************
The following NEW packages will be installed:
  prometheus-mysqld-exporter
0 upgraded, 1 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]
The following NEW packages will be installed:
  prometheus-mysqld-exporter
0 upgraded, 1 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]

TASK [mysql : Create exporter user] ********************************************
changed: [1nnu-1]
changed: [1nnu-2]

TASK [mysql : Copy .my.cnf to /var/lib/prometheus/.my.cnf] *********************
changed: [1nnu-1]
changed: [1nnu-2]

RUNNING HANDLER [mysql : Restart MySQL] ****************************************
changed: [1nnu-1]
changed: [1nnu-2]

RUNNING HANDLER [mysql : Restart node exporter] ********************************
changed: [1nnu-2]
changed: [1nnu-1]

RUNNING HANDLER [mysql : Reset MySQL source] ***********************************
skipping: [1nnu-2] => (item=stopslave) 
skipping: [1nnu-2] => (item=resetmaster) 
changed: [1nnu-1] => (item=stopslave)
changed: [1nnu-1] => (item=resetmaster)

RUNNING HANDLER [mysql : Reset MySQL replica] **********************************
skipping: [1nnu-1] => (item=stopslave) 
skipping: [1nnu-1] => (item=changemaster) 
skipping: [1nnu-1] => (item=resetslave) 
skipping: [1nnu-1] => (item=startslave) 
changed: [1nnu-2] => (item=stopslave)
changed: [1nnu-2] => (item=changemaster)
changed: [1nnu-2] => (item=resetslave)
changed: [1nnu-2] => (item=startslave)

TASK [mysql : Check mysql enabled and started] *********************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Check node exporter started] *************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Create directory mysql backup] ***********************************
--- before
+++ after
@@ -1,6 +1,6 @@
 {
-    "mode": "0755",
-    "owner": 0,
+    "mode": "0400",
+    "owner": 34,
     "path": "/home/backup/mysql",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-2]
--- before
+++ after
@@ -1,6 +1,6 @@
 {
-    "mode": "0755",
-    "owner": 0,
+    "mode": "0400",
+    "owner": 34,
     "path": "/home/backup/mysql",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-1]

TASK [mysql : Create backup as database user] **********************************
changed: [1nnu-1]
changed: [1nnu-2]

TASK [mysql : Copy .my.cnf to /home/backup/.my.cnf] ****************************
changed: [1nnu-1]
changed: [1nnu-2]

TASK [mysql : Copy cron schedule file] *****************************************
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmppujenkpq/mysql-backup
@@ -0,0 +1 @@
+

changed: [1nnu-1]
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpqy3px0y0/mysql-backup
@@ -0,0 +1,2 @@
+18 22 * * * backup mysqldump agama > /home/backup/mysql/agama.sql
+19 22 * * * backup duplicity --no-encryption full /home/backup/mysql/ rsync://1nnu@backup.pingix.ttu/mysql

changed: [1nnu-2]

TASK [mysql : MySQL user for replication] **************************************
changed: [1nnu-1]
changed: [1nnu-2]

TASK [mysql : MySQL read only mode] ********************************************
changed: [1nnu-1]
changed: [1nnu-2]

TASK [mysql : Add mysql CNAME records] *****************************************
changed: [1nnu-2]
changed: [1nnu-1]

RUNNING HANDLER [mysql : Reset MySQL source] ***********************************
skipping: [1nnu-2] => (item=stopslave) 
skipping: [1nnu-2] => (item=resetmaster) 
changed: [1nnu-1] => (item=stopslave)
changed: [1nnu-1] => (item=resetmaster)

RUNNING HANDLER [mysql : Reset MySQL replica] **********************************
skipping: [1nnu-1] => (item=stopslave) 
skipping: [1nnu-1] => (item=changemaster) 
skipping: [1nnu-1] => (item=resetslave) 
skipping: [1nnu-1] => (item=startslave) 
changed: [1nnu-2] => (item=stopslave)
changed: [1nnu-2] => (item=changemaster)
changed: [1nnu-2] => (item=resetslave)
changed: [1nnu-2] => (item=startslave)

PLAY [Web server] **************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [nginx : Install nginx from APT] ******************************************
The following additional packages will be installed:
  fontconfig-config fonts-dejavu-core libdeflate0 libfontconfig1 libgd3
  libjbig0 libjpeg-turbo8 libjpeg8 libnginx-mod-http-geoip2
  libnginx-mod-http-image-filter libnginx-mod-http-xslt-filter
  libnginx-mod-mail libnginx-mod-stream libnginx-mod-stream-geoip2 libtiff5
  libwebp7 libxpm4 nginx-common nginx-core
Suggested packages:
  libgd-tools fcgiwrap nginx-doc ssl-cert
The following NEW packages will be installed:
  fontconfig-config fonts-dejavu-core libdeflate0 libfontconfig1 libgd3
  libjbig0 libjpeg-turbo8 libjpeg8 libnginx-mod-http-geoip2
  libnginx-mod-http-image-filter libnginx-mod-http-xslt-filter
  libnginx-mod-mail libnginx-mod-stream libnginx-mod-stream-geoip2 libtiff5
  libwebp7 libxpm4 nginx nginx-common nginx-core prometheus-nginx-exporter
0 upgraded, 21 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]
The following additional packages will be installed:
  fontconfig-config fonts-dejavu-core libdeflate0 libfontconfig1 libgd3
  libjbig0 libjpeg-turbo8 libjpeg8 libnginx-mod-http-geoip2
  libnginx-mod-http-image-filter libnginx-mod-http-xslt-filter
  libnginx-mod-mail libnginx-mod-stream libnginx-mod-stream-geoip2 libtiff5
  libwebp7 libxpm4 nginx-common nginx-core
Suggested packages:
  libgd-tools fcgiwrap nginx-doc ssl-cert
The following NEW packages will be installed:
  fontconfig-config fonts-dejavu-core libdeflate0 libfontconfig1 libgd3
  libjbig0 libjpeg-turbo8 libjpeg8 libnginx-mod-http-geoip2
  libnginx-mod-http-image-filter libnginx-mod-http-xslt-filter
  libnginx-mod-mail libnginx-mod-stream libnginx-mod-stream-geoip2 libtiff5
  libwebp7 libxpm4 nginx nginx-common nginx-core prometheus-nginx-exporter
0 upgraded, 21 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]

TASK [nginx : nginx configuration] *********************************************
--- before: /etc/nginx/sites-enabled/default
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmp1_b9oqig/default.j2
@@ -1,91 +1,18 @@
-##
-# You should look at the following URL's in order to grasp a solid understanding
-# of Nginx configuration files in order to fully unleash the power of Nginx.
-# https://www.nginx.com/resources/wiki/start/
-# https://www.nginx.com/resources/wiki/start/topics/tutorials/config_pitfalls/
-# https://wiki.debian.org/Nginx/DirectoryStructure
-#
-# In most cases, administrators will remove this file from sites-enabled/ and
-# leave it as reference inside of sites-available where it will continue to be
-# updated by the nginx packaging team.
-#
-# This file will automatically load configuration files provided by other
-# applications, such as Drupal or Wordpress. These applications will be made
-# available underneath a path with that package name, such as /drupal8.
-#
-# Please see /usr/share/doc/nginx-doc/examples/ for more detailed examples.
-##
-
-# Default server configuration
-#
 server {
-	listen 80 default_server;
-	listen [::]:80 default_server;
-
-	# SSL configuration
-	#
-	# listen 443 ssl default_server;
-	# listen [::]:443 ssl default_server;
-	#
-	# Note: You should disable gzip for SSL traffic.
-	# See: https://bugs.debian.org/773332
-	#
-	# Read up on ssl_ciphers to ensure a secure configuration.
-	# See: https://bugs.debian.org/765782
-	#
-	# Self signed certs generated by the ssl-cert package
-	# Don't use them in a production server!
-	#
-	# include snippets/snakeoil.conf;
-
-	root /var/www/html;
-
-	# Add index.php to the list if you are using PHP
-	index index.html index.htm index.nginx-debian.html;
-
-	server_name _;
-
-	location / {
-		# First attempt to serve request as file, then
-		# as directory, then fall back to displaying a 404.
-		try_files $uri $uri/ =404;
-	}
-
-	# pass PHP scripts to FastCGI server
-	#
-	#location ~ \.php$ {
-	#	include snippets/fastcgi-php.conf;
-	#
-	#	# With php-fpm (or other unix sockets):
-	#	fastcgi_pass unix:/run/php/php7.4-fpm.sock;
-	#	# With php-cgi (or other tcp sockets):
-	#	fastcgi_pass 127.0.0.1:9000;
-	#}
-
-	# deny access to .htaccess files, if Apache's document root
-	# concurs with nginx's one
-	#
-	#location ~ /\.ht {
-	#	deny all;
-	#}
+    listen 80 default_server;
+    server_name _;
+	
+	    location / {
+        proxy_pass http://localhost:8001;
+    }
+	
+    	
 }
 
+server {
+	listen 8080 default_server;
+	location /stub_status {
+		stub_status;
+	}
+}
 
-# Virtual Host configuration for example.com
-#
-# You can move that to a different file under sites-available/ and symlink that
-# to sites-enabled/ to enable it.
-#
-#server {
-#	listen 80;
-#	listen [::]:80;
-#
-#	server_name example.com;
-#
-#	root /var/www/example.com;
-#	index index.html;
-#
-#	location / {
-#		try_files $uri $uri/ =404;
-#	}
-#}

changed: [1nnu-1]
--- before: /etc/nginx/sites-enabled/default
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpi948gnvf/default.j2
@@ -1,91 +1,18 @@
-##
-# You should look at the following URL's in order to grasp a solid understanding
-# of Nginx configuration files in order to fully unleash the power of Nginx.
-# https://www.nginx.com/resources/wiki/start/
-# https://www.nginx.com/resources/wiki/start/topics/tutorials/config_pitfalls/
-# https://wiki.debian.org/Nginx/DirectoryStructure
-#
-# In most cases, administrators will remove this file from sites-enabled/ and
-# leave it as reference inside of sites-available where it will continue to be
-# updated by the nginx packaging team.
-#
-# This file will automatically load configuration files provided by other
-# applications, such as Drupal or Wordpress. These applications will be made
-# available underneath a path with that package name, such as /drupal8.
-#
-# Please see /usr/share/doc/nginx-doc/examples/ for more detailed examples.
-##
-
-# Default server configuration
-#
 server {
-	listen 80 default_server;
-	listen [::]:80 default_server;
-
-	# SSL configuration
-	#
-	# listen 443 ssl default_server;
-	# listen [::]:443 ssl default_server;
-	#
-	# Note: You should disable gzip for SSL traffic.
-	# See: https://bugs.debian.org/773332
-	#
-	# Read up on ssl_ciphers to ensure a secure configuration.
-	# See: https://bugs.debian.org/765782
-	#
-	# Self signed certs generated by the ssl-cert package
-	# Don't use them in a production server!
-	#
-	# include snippets/snakeoil.conf;
-
-	root /var/www/html;
-
-	# Add index.php to the list if you are using PHP
-	index index.html index.htm index.nginx-debian.html;
-
-	server_name _;
-
-	location / {
-		# First attempt to serve request as file, then
-		# as directory, then fall back to displaying a 404.
-		try_files $uri $uri/ =404;
-	}
-
-	# pass PHP scripts to FastCGI server
-	#
-	#location ~ \.php$ {
-	#	include snippets/fastcgi-php.conf;
-	#
-	#	# With php-fpm (or other unix sockets):
-	#	fastcgi_pass unix:/run/php/php7.4-fpm.sock;
-	#	# With php-cgi (or other tcp sockets):
-	#	fastcgi_pass 127.0.0.1:9000;
-	#}
-
-	# deny access to .htaccess files, if Apache's document root
-	# concurs with nginx's one
-	#
-	#location ~ /\.ht {
-	#	deny all;
-	#}
+    listen 80 default_server;
+    server_name _;
+	
+	    location / {
+        proxy_pass http://localhost:8001;
+    }
+	
+    	
 }
 
+server {
+	listen 8080 default_server;
+	location /stub_status {
+		stub_status;
+	}
+}
 
-# Virtual Host configuration for example.com
-#
-# You can move that to a different file under sites-available/ and symlink that
-# to sites-enabled/ to enable it.
-#
-#server {
-#	listen 80;
-#	listen [::]:80;
-#
-#	server_name example.com;
-#
-#	root /var/www/example.com;
-#	index index.html;
-#
-#	location / {
-#		try_files $uri $uri/ =404;
-#	}
-#}

changed: [1nnu-2]

RUNNING HANDLER [nginx : restart nginx] ****************************************
changed: [1nnu-2]
changed: [1nnu-1]

RUNNING HANDLER [nginx : restart nginx-exporter] *******************************
changed: [1nnu-2]
changed: [1nnu-1]

TASK [nginx : nginx service] ***************************************************
ok: [1nnu-1] => (item=nginx)
ok: [1nnu-2] => (item=nginx)
ok: [1nnu-1] => (item=prometheus-nginx-exporter)
ok: [1nnu-2] => (item=prometheus-nginx-exporter)

TASK [keepalived : Add user "keepalived_script"] *******************************
changed: [1nnu-1]
changed: [1nnu-2]

TASK [keepalived : Install keepalived] *****************************************
The following additional packages will be installed:
  ipvsadm libsensors-config libsensors5 libsnmp-base libsnmp40
Suggested packages:
  heartbeat ldirectord lm-sensors snmp-mibs-downloader
The following NEW packages will be installed:
  ipvsadm keepalived libsensors-config libsensors5 libsnmp-base libsnmp40
0 upgraded, 6 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]
The following additional packages will be installed:
  ipvsadm libsensors-config libsensors5 libsnmp-base libsnmp40
Suggested packages:
  heartbeat ldirectord lm-sensors snmp-mibs-downloader
The following NEW packages will be installed:
  ipvsadm keepalived libsensors-config libsensors5 libsnmp-base libsnmp40
0 upgraded, 6 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]

TASK [keepalived : Copy keepalived config] *************************************
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmplidj6304/keepalived.conf.j2
@@ -0,0 +1,27 @@
+global_defs {
+    enable_script_security
+    script_user keepalived_script
+}
+
+vrrp_script check_haproxy {                 
+    script "/home/keepalived_script/vrrp_script" 
+    weight 20                              
+    interval 1               
+}
+vrrp_instance pingix.ttu {             
+    interface ens3
+    virtual_router_id 1
+        priority 109
+        advert_int 1                            
+    virtual_ipaddress {                     
+        192.168.100.43/24
+    }
+    unicast_peer {                          
+                            
+                192.168.42.43
+                                    
+                    }
+    track_script {
+        check_haproxy
+    }
+}
\ No newline at end of file

changed: [1nnu-2]
--- before
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpko7bbhmi/keepalived.conf.j2
@@ -0,0 +1,27 @@
+global_defs {
+    enable_script_security
+    script_user keepalived_script
+}
+
+vrrp_script check_haproxy {                 
+    script "/home/keepalived_script/vrrp_script" 
+    weight 20                              
+    interval 1               
+}
+vrrp_instance pingix.ttu {             
+    interface ens3
+    virtual_router_id 1
+        priority 110
+        advert_int 1                            
+    virtual_ipaddress {                     
+        192.168.100.43/24
+    }
+    unicast_peer {                          
+                            
+                                    
+                192.168.42.138
+                    }
+    track_script {
+        check_haproxy
+    }
+}
\ No newline at end of file

changed: [1nnu-1]

TASK [keepalived : Copy keepalived script file] ********************************
--- before
+++ after: /home/innar/ica0002/roles/keepalived/files/vrrp_script
@@ -0,0 +1,2 @@
+#!/bin/bash
+ss -ntl | grep -q ':88 '
\ No newline at end of file

changed: [1nnu-1]
--- before
+++ after: /home/innar/ica0002/roles/keepalived/files/vrrp_script
@@ -0,0 +1,2 @@
+#!/bin/bash
+ss -ntl | grep -q ':88 '
\ No newline at end of file

changed: [1nnu-2]

TASK [keepalived : Start and enable keepalived] ********************************
changed: [1nnu-1]
changed: [1nnu-2]

TASK [keepalived : Download keepalived exporter] *******************************
Selecting previously unselected package keepalived-exporter.
(Reading database ... 59353 files and directories currently installed.)
Preparing to unpack .../keepalived-exporter_1.4.0_linux_amd64rssf6ezx.deb ...
Unpacking keepalived-exporter (1.4.0) ...
Setting up keepalived-exporter (1.4.0) ...
changed: [1nnu-2]
Selecting previously unselected package keepalived-exporter.
(Reading database ... 59353 files and directories currently installed.)
Preparing to unpack .../keepalived-exporter_1.4.0_linux_amd64nngj_tjb.deb ...
Unpacking keepalived-exporter (1.4.0) ...
Setting up keepalived-exporter (1.4.0) ...
changed: [1nnu-1]

TASK [keepalived : Copy keepalived exporter service file] **********************
--- before
+++ after: /home/innar/ica0002/roles/keepalived/files/keepalived_exporter.service
@@ -0,0 +1,8 @@
+After=network-online.target
+
+[Service]
+User=root
+ExecStart=/usr/bin/keepalived-exporter
+
+[Install]
+WantedBy=multi-user.target

changed: [1nnu-2]
--- before
+++ after: /home/innar/ica0002/roles/keepalived/files/keepalived_exporter.service
@@ -0,0 +1,8 @@
+After=network-online.target
+
+[Service]
+User=root
+ExecStart=/usr/bin/keepalived-exporter
+
+[Install]
+WantedBy=multi-user.target

changed: [1nnu-1]

TASK [keepalived : Start and enable keepalived exporter] ***********************
changed: [1nnu-1]
changed: [1nnu-2]

TASK [haproxy : Install HAproxy] ***********************************************
The following additional packages will be installed:
  liblua5.3-0
Suggested packages:
  vim-haproxy haproxy-doc
The following NEW packages will be installed:
  haproxy liblua5.3-0
0 upgraded, 2 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]
The following additional packages will be installed:
  liblua5.3-0
Suggested packages:
  vim-haproxy haproxy-doc
The following NEW packages will be installed:
  haproxy liblua5.3-0
0 upgraded, 2 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]

TASK [haproxy : Copy haproxy conf file] ****************************************
--- before: /etc/haproxy/haproxy.cfg
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmpnsep5wlb/haproxy.cfg.j2
@@ -1,34 +1,49 @@
 global
-	log /dev/log	local0
-	log /dev/log	local1 notice
-	chroot /var/lib/haproxy
-	stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
-	stats timeout 30s
-	user haproxy
-	group haproxy
-	daemon
+        log /dev/log    local0
+        log /dev/log    local1 notice
+        chroot /var/lib/haproxy
+        stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
+        stats timeout 30s
+        user haproxy
+        group haproxy
+        daemon
 
-	# Default SSL material locations
-	ca-base /etc/ssl/certs
-	crt-base /etc/ssl/private
+        # Default SSL material locations
+        ca-base /etc/ssl/certs
+        crt-base /etc/ssl/private
 
-	# See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
+        # See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
         ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
         ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
         ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets
 
 defaults
-	log	global
-	mode	http
-	option	httplog
-	option	dontlognull
+        log     global
+        mode    http
+        option  httplog
+        option  dontlognull
         timeout connect 5000
         timeout client  50000
         timeout server  50000
-	errorfile 400 /etc/haproxy/errors/400.http
-	errorfile 403 /etc/haproxy/errors/403.http
-	errorfile 408 /etc/haproxy/errors/408.http
-	errorfile 500 /etc/haproxy/errors/500.http
-	errorfile 502 /etc/haproxy/errors/502.http
-	errorfile 503 /etc/haproxy/errors/503.http
-	errorfile 504 /etc/haproxy/errors/504.http
+        errorfile 400 /etc/haproxy/errors/400.http
+        errorfile 403 /etc/haproxy/errors/403.http
+        errorfile 408 /etc/haproxy/errors/408.http
+        errorfile 500 /etc/haproxy/errors/500.http
+        errorfile 502 /etc/haproxy/errors/502.http
+        errorfile 503 /etc/haproxy/errors/503.http
+        errorfile 504 /etc/haproxy/errors/504.http
+
+frontend my_ha_frontend
+    bind :88
+    default_backend my_ha_backend
+
+backend my_ha_backend
+            server agama1-1 1nnu-1:8001 check
+            server agama2-2 1nnu-1:8002 check
+            server agama1-3 1nnu-2:8001 check
+            server agama2-4 1nnu-2:8002 check
+        
+listen stats
+    bind :9188
+    stats enable
+    stats uri /metrics

changed: [1nnu-2]
--- before: /etc/haproxy/haproxy.cfg
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmplp31qjc1/haproxy.cfg.j2
@@ -1,34 +1,49 @@
 global
-	log /dev/log	local0
-	log /dev/log	local1 notice
-	chroot /var/lib/haproxy
-	stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
-	stats timeout 30s
-	user haproxy
-	group haproxy
-	daemon
+        log /dev/log    local0
+        log /dev/log    local1 notice
+        chroot /var/lib/haproxy
+        stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
+        stats timeout 30s
+        user haproxy
+        group haproxy
+        daemon
 
-	# Default SSL material locations
-	ca-base /etc/ssl/certs
-	crt-base /etc/ssl/private
+        # Default SSL material locations
+        ca-base /etc/ssl/certs
+        crt-base /etc/ssl/private
 
-	# See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
+        # See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
         ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
         ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
         ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets
 
 defaults
-	log	global
-	mode	http
-	option	httplog
-	option	dontlognull
+        log     global
+        mode    http
+        option  httplog
+        option  dontlognull
         timeout connect 5000
         timeout client  50000
         timeout server  50000
-	errorfile 400 /etc/haproxy/errors/400.http
-	errorfile 403 /etc/haproxy/errors/403.http
-	errorfile 408 /etc/haproxy/errors/408.http
-	errorfile 500 /etc/haproxy/errors/500.http
-	errorfile 502 /etc/haproxy/errors/502.http
-	errorfile 503 /etc/haproxy/errors/503.http
-	errorfile 504 /etc/haproxy/errors/504.http
+        errorfile 400 /etc/haproxy/errors/400.http
+        errorfile 403 /etc/haproxy/errors/403.http
+        errorfile 408 /etc/haproxy/errors/408.http
+        errorfile 500 /etc/haproxy/errors/500.http
+        errorfile 502 /etc/haproxy/errors/502.http
+        errorfile 503 /etc/haproxy/errors/503.http
+        errorfile 504 /etc/haproxy/errors/504.http
+
+frontend my_ha_frontend
+    bind :88
+    default_backend my_ha_backend
+
+backend my_ha_backend
+            server agama1-1 1nnu-1:8001 check
+            server agama2-2 1nnu-1:8002 check
+            server agama1-3 1nnu-2:8001 check
+            server agama2-4 1nnu-2:8002 check
+        
+listen stats
+    bind :9188
+    stats enable
+    stats uri /metrics

changed: [1nnu-1]

TASK [haproxy : Start and enable haproxy] **************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Install haproxy exporter] **************************************
The following NEW packages will be installed:
  prometheus-haproxy-exporter
0 upgraded, 1 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-2]
The following NEW packages will be installed:
  prometheus-haproxy-exporter
0 upgraded, 1 newly installed, 0 to remove and 129 not upgraded.
changed: [1nnu-1]

TASK [haproxy : Copy haproxy exporter conf file] *******************************
--- before: /etc/default/prometheus-haproxy-exporter
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmp6f5uq7j_/prometheus-haproxy-exporter.j2
@@ -1,35 +1 @@
-# Set the command-line arguments to pass to the server.
-# Due to shell scaping, to pass backslashes for regexes, you need to double
-# them (\\d for \d). If running under systemd, you need to double them again
-# (\\\\d to mean \d), and escape newlines too.
-ARGS=""
-
-# Prometheus-haproxy-exporter supports the following options:
-#
-#  --web.listen-address=":9101"
-#    Address to listen on for web interface and telemetry.
-#  --web.telemetry-path="/metrics"
-#    Path under which to expose metrics.
-#  --haproxy.scrape-uri="http://localhost/;csv"
-#    URI on which to scrape HAProxy.
-#  --haproxy.ssl-verify
-#    Flag that enables SSL certificate verification for the scrape URI
-#  --haproxy.server-metric-fields="2,3,4,5,6,7,8,9,13,14,15,16,17,18,21,24,33,35,38,39,40,41,42,43,44"
-#    Comma-separated list of exported server metrics. See
-#    http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#9.1
-#  --haproxy.timeout=5s
-#    Timeout for trying to get stats from HAProxy.
-#  --haproxy.pid-file=""
-#    Path to HAProxy pid file.
-#
-#    If provided, the standard process metrics get exported for the HAProxy
-#    process, prefixed with 'haproxy_process_...'. The haproxy_process exporter
-#    needs to have read access to files owned by the HAProxy process. Depends
-#    on the availability of /proc.
-#    https://prometheus.io/docs/instrumenting/writing_clientlibs/#process-metrics.
-#  --log.level="info"
-#    Only log messages with the given severity or above.
-#    Valid levels: [debug, info, warn, error, fatal]
-#  --log.format="logger:stderr"
-#    Set the log target and format. Example:
-#    "logger:syslog?appname=bob&local=7" or "logger:stdout?json=true"
+ARGS="--haproxy.scrape-uri=http://localhost:9188/metrics;csv"

changed: [1nnu-1]
--- before: /etc/default/prometheus-haproxy-exporter
+++ after: /home/innar/.ansible/tmp/ansible-local-1110dybss91t/tmp5cdsx9qi/prometheus-haproxy-exporter.j2
@@ -1,35 +1 @@
-# Set the command-line arguments to pass to the server.
-# Due to shell scaping, to pass backslashes for regexes, you need to double
-# them (\\d for \d). If running under systemd, you need to double them again
-# (\\\\d to mean \d), and escape newlines too.
-ARGS=""
-
-# Prometheus-haproxy-exporter supports the following options:
-#
-#  --web.listen-address=":9101"
-#    Address to listen on for web interface and telemetry.
-#  --web.telemetry-path="/metrics"
-#    Path under which to expose metrics.
-#  --haproxy.scrape-uri="http://localhost/;csv"
-#    URI on which to scrape HAProxy.
-#  --haproxy.ssl-verify
-#    Flag that enables SSL certificate verification for the scrape URI
-#  --haproxy.server-metric-fields="2,3,4,5,6,7,8,9,13,14,15,16,17,18,21,24,33,35,38,39,40,41,42,43,44"
-#    Comma-separated list of exported server metrics. See
-#    http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#9.1
-#  --haproxy.timeout=5s
-#    Timeout for trying to get stats from HAProxy.
-#  --haproxy.pid-file=""
-#    Path to HAProxy pid file.
-#
-#    If provided, the standard process metrics get exported for the HAProxy
-#    process, prefixed with 'haproxy_process_...'. The haproxy_process exporter
-#    needs to have read access to files owned by the HAProxy process. Depends
-#    on the availability of /proc.
-#    https://prometheus.io/docs/instrumenting/writing_clientlibs/#process-metrics.
-#  --log.level="info"
-#    Only log messages with the given severity or above.
-#    Valid levels: [debug, info, warn, error, fatal]
-#  --log.format="logger:stderr"
-#    Set the log target and format. Example:
-#    "logger:syslog?appname=bob&local=7" or "logger:stdout?json=true"
+ARGS="--haproxy.scrape-uri=http://localhost:9188/metrics;csv"

changed: [1nnu-2]

TASK [haproxy : Start and enable haproxy-exporter] *****************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Gather facts for the first dns_primary host] *******************
ok: [1nnu-1 -> 193.40.156.67]
ok: [1nnu-2 -> 193.40.156.67]

TASK [haproxy : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Add haproxy CNAME records] *************************************
changed: [1nnu-2 -> 193.40.156.67]
changed: [1nnu-1 -> 193.40.156.67]

TASK [agama : Create directory for agama user] *********************************
--- before
+++ after
@@ -1,4 +1,4 @@
 {
     "path": "/opt/agama",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-2]
--- before
+++ after
@@ -1,4 +1,4 @@
 {
     "path": "/opt/agama",
-    "state": "absent"
+    "state": "directory"
 }

changed: [1nnu-1]

TASK [agama : Download agama dockerfile] ***************************************
changed: [1nnu-2] => (item=agama.py)
changed: [1nnu-1] => (item=agama.py)
changed: [1nnu-1] => (item=Dockerfile)
changed: [1nnu-2] => (item=Dockerfile)

TASK [agama : Build agama image] ***********************************************
changed: [1nnu-2]
changed: [1nnu-1]

TASK [agama : Get container info] **********************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [agama : Start agama containers] ******************************************
changed: [1nnu-2] => (item=None)
changed: [1nnu-1] => (item=None)
changed: [1nnu-1] => (item=None)
changed: [1nnu-2] => (item=None)
changed: [1nnu-1]
changed: [1nnu-2]

TASK [agama : Remove unnecessary agama containers] *****************************

TASK [agama : Gather facts for the first dns_primary host] *********************
ok: [1nnu-1 -> 193.40.156.67]
ok: [1nnu-2 -> 193.40.156.67]

TASK [agama : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-1]
ok: [1nnu-2]

TASK [agama : Add agama CNAME records] *****************************************
changed: [1nnu-2]
changed: [1nnu-1]

RUNNING HANDLER [keepalived : Restart keepalived] ******************************
changed: [1nnu-2]
changed: [1nnu-1]

RUNNING HANDLER [haproxy : Restart haproxy] ************************************
changed: [1nnu-2]
changed: [1nnu-1]

RUNNING HANDLER [haproxy : Restart haproxy-exporter] ***************************
changed: [1nnu-2]
changed: [1nnu-1]

PLAY RECAP *********************************************************************
1nnu-1                     : ok=88   changed=66   unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
1nnu-2                     : ok=88   changed=65   unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
1nnu-3                     : ok=84   changed=64   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

+ ansible-playbook infra.yaml --diff
[WARNING]: Collection community.general does not support Ansible version 2.10.8

PLAY [Initial setup] ***********************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-3]
ok: [1nnu-1]
ok: [1nnu-2]

TASK [init : Update APT cache] *************************************************
ok: [1nnu-3]
ok: [1nnu-2]
ok: [1nnu-1]

TASK [init : Install prometehus-node-exporter from APT] ************************
ok: [1nnu-3]
ok: [1nnu-1]
ok: [1nnu-2]

TASK [init : ansible.builtin.service] ******************************************
ok: [1nnu-3]
ok: [1nnu-1]
ok: [1nnu-2]

TASK [init : Install rsyslog] **************************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [init : Start and enable rsyslog] *****************************************
ok: [1nnu-3]
ok: [1nnu-1]
ok: [1nnu-2]

TASK [init : Copy rsyslog config] **********************************************
ok: [1nnu-3]
ok: [1nnu-1]
ok: [1nnu-2]

TASK [init : Create backup user with RSA key] **********************************
ok: [1nnu-3]
ok: [1nnu-1]
ok: [1nnu-2]

TASK [init : Add backup server public key to known hosts] **********************
ok: [1nnu-1]
ok: [1nnu-3]
ok: [1nnu-2]

TASK [init : Create directory restore dir for backup] **************************
ok: [1nnu-1]
ok: [1nnu-3]
ok: [1nnu-2]

TASK [init : Install duplicity] ************************************************
ok: [1nnu-2]
ok: [1nnu-3]
ok: [1nnu-1]

PLAY [Dns server] **************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [bind : Install Bind9] ****************************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [bind : Install dnspython] ************************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [bind : Copy bind config] *************************************************
ok: [1nnu-3] => (item=None)
ok: [1nnu-2] => (item=None)
ok: [1nnu-1] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3]
ok: [1nnu-1] => (item=None)
ok: [1nnu-1]
ok: [1nnu-2] => (item=None)
ok: [1nnu-2]

TASK [bind : Copy master zone] *************************************************
ok: [1nnu-1] => (item=None)
ok: [1nnu-2] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-1] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-1]
ok: [1nnu-3]
ok: [1nnu-2] => (item=None)
ok: [1nnu-2]

TASK [bind : Unarchive bind exporter] ******************************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [bind : link file] ********************************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [bind : Copy bind exporter service definition] ****************************
ok: [1nnu-3]
ok: [1nnu-2]
ok: [1nnu-1]

TASK [bind : Reload systemd] ***************************************************
ok: [1nnu-2]
ok: [1nnu-3]
ok: [1nnu-1]

TASK [bind : bind service] *****************************************************
ok: [1nnu-1] => (item=bind9)
ok: [1nnu-3] => (item=bind9)
ok: [1nnu-2] => (item=bind9)
ok: [1nnu-1] => (item=prometheus-bind-exporter)
ok: [1nnu-3] => (item=prometheus-bind-exporter)
ok: [1nnu-2] => (item=prometheus-bind-exporter)

TASK [bind : Add backup server A records] **************************************
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1]
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2]
ok: [1nnu-3] => (item=None)
ok: [1nnu-3]

TASK [bind : Add backup server CNAME records] **********************************
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1]
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2]
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3]

PLAY [Resolv] ******************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [resolv : Disable systemd-resolved] ***************************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [resolv : Copy /etc/resolv.conf to hosts] *********************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

PLAY [Docker] ******************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [docker : Install Docker] *************************************************
ok: [1nnu-2]
ok: [1nnu-3]
ok: [1nnu-1]

TASK [docker : Check docker enabled] *******************************************
ok: [1nnu-3]
ok: [1nnu-1]
ok: [1nnu-2]

TASK [docker : Install python3-docker] *****************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

PLAY [Prometheus + grafana] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-3]

TASK [prometheus : Install prometheus] *****************************************
ok: [1nnu-3]

TASK [prometheus : Put prometheus args] ****************************************
ok: [1nnu-3]

TASK [prometheus : Configure prometheus] ***************************************
ok: [1nnu-3]

TASK [prometheus : ansible.builtin.service] ************************************
ok: [1nnu-3]

TASK [prometheus : Add prometheus CNAME records] *******************************
ok: [1nnu-3]

TASK [grafana : Grafana directory] *********************************************
ok: [1nnu-3] => (item=/opt/grafana/provisioning/dashboards)
ok: [1nnu-3] => (item=/opt/grafana/provisioning/datasources)

TASK [grafana : Grafana configuration] *****************************************
ok: [1nnu-3]

TASK [grafana : Copy datasource.yml.j2] ****************************************
ok: [1nnu-3]

TASK [grafana : Configure dashboards] ******************************************
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3]

TASK [grafana : Change grafana config] *****************************************
ok: [1nnu-3]

TASK [grafana : Grafana Docker container] **************************************
[DEPRECATION WARNING]: The container_default_behavior option will change its 
default value from "compatibility" to "no_defaults" in community.docker 2.0.0. 
To remove this warning, please specify an explicit value for it now. This 
feature will be removed from community.docker in version 2.0.0. Deprecation 
warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
ok: [1nnu-3]

TASK [grafana : Gather facts for the first dns_primary host] *******************
ok: [1nnu-3 -> 193.40.156.67]

TASK [grafana : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-3]

TASK [grafana : Add grafana CNAME records] *************************************
ok: [1nnu-3]

TASK [nginx : Install nginx from APT] ******************************************
ok: [1nnu-3]

TASK [nginx : nginx configuration] *********************************************
ok: [1nnu-3]

TASK [nginx : nginx service] ***************************************************
ok: [1nnu-3] => (item=nginx)
ok: [1nnu-3] => (item=prometheus-nginx-exporter)

PLAY [InfluxDb] ****************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-3]

TASK [influxdb : add influx gpg key] *******************************************
ok: [1nnu-3]

TASK [influxdb : add influx repo] **********************************************
ok: [1nnu-3]

TASK [influxdb : Install influx] ***********************************************
ok: [1nnu-3]

TASK [influxdb : Copy influxdb config] *****************************************
ok: [1nnu-3]

TASK [influxdb : influxdb started] *********************************************
ok: [1nnu-3]

TASK [influxdb : Install telegraf] *********************************************
ok: [1nnu-3]

TASK [influxdb : Copy telegraf conf] *******************************************
ok: [1nnu-3]

TASK [influxdb : telegraf] *****************************************************
ok: [1nnu-3]

TASK [influxdb : Download Influxdb exporter] ***********************************
ok: [1nnu-3]

TASK [influxdb : Copy influx exporter service file] ****************************
ok: [1nnu-3]

TASK [influxdb : Start and enable influx exporter] *****************************
ok: [1nnu-3]

TASK [influxdb : Create directory for influxdb backup] *************************
ok: [1nnu-3]

TASK [influxdb : Copy cron schedule file] **************************************
ok: [1nnu-3]

TASK [influxdb : Gather facts for the first dns_primary host] ******************
ok: [1nnu-3 -> 193.40.156.67]

TASK [influxdb : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-3]

TASK [influxdb : Add influxdb CNAME records] ***********************************
ok: [1nnu-3]

TASK [agama_client : Add agama-client as system user] **************************
ok: [1nnu-3]

TASK [agama_client : Install fping] ********************************************
ok: [1nnu-3]

TASK [agama_client : copy script to /usr/local/bin/agama-client] ***************
ok: [1nnu-3]

TASK [agama_client : copy service definition to /etc/systemd/system/] **********
ok: [1nnu-3]

TASK [agama_client : Reload systemd] *******************************************
ok: [1nnu-3]

TASK [agama_client : Create directory agama-client app conf dir] ***************
ok: [1nnu-3]

TASK [agama_client : copy conf to to /etc/agama-client/] ***********************
ok: [1nnu-3]

TASK [agama_client : agama-client started] *************************************
ok: [1nnu-3]

PLAY [Database server] *********************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Install mysql-server from APT] ***********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Mysql configuration] *********************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Install PyMySql from APT] ****************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Check mysql enabled and started] *********************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Create database] *************************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Create agama as database user] ***********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Install mysql exporter] ******************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Create exporter user] ********************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Copy .my.cnf to /var/lib/prometheus/.my.cnf] *********************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Check mysql enabled and started] *********************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Check node exporter started] *************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Create directory mysql backup] ***********************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Create backup as database user] **********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Copy .my.cnf to /home/backup/.my.cnf] ****************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Copy cron schedule file] *****************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : MySQL user for replication] **************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : MySQL read only mode] ********************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Add mysql CNAME records] *****************************************
ok: [1nnu-1]
ok: [1nnu-2]

PLAY [Web server] **************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [nginx : Install nginx from APT] ******************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [nginx : nginx configuration] *********************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [nginx : nginx service] ***************************************************
ok: [1nnu-1] => (item=nginx)
ok: [1nnu-2] => (item=nginx)
ok: [1nnu-1] => (item=prometheus-nginx-exporter)
ok: [1nnu-2] => (item=prometheus-nginx-exporter)

TASK [keepalived : Add user "keepalived_script"] *******************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Install keepalived] *****************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Copy keepalived config] *************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Copy keepalived script file] ********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Start and enable keepalived] ********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Download keepalived exporter] *******************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Copy keepalived exporter service file] **********************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Start and enable keepalived exporter] ***********************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Install HAproxy] ***********************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Copy haproxy conf file] ****************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [haproxy : Start and enable haproxy] **************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [haproxy : Install haproxy exporter] **************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [haproxy : Copy haproxy exporter conf file] *******************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Start and enable haproxy-exporter] *****************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Gather facts for the first dns_primary host] *******************
ok: [1nnu-1 -> 193.40.156.67]
ok: [1nnu-2 -> 193.40.156.67]

TASK [haproxy : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Add haproxy CNAME records] *************************************
ok: [1nnu-2 -> 193.40.156.67]
ok: [1nnu-1 -> 193.40.156.67]

TASK [agama : Create directory for agama user] *********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [agama : Download agama dockerfile] ***************************************
ok: [1nnu-2] => (item=agama.py)
ok: [1nnu-1] => (item=agama.py)
ok: [1nnu-1] => (item=Dockerfile)
ok: [1nnu-2] => (item=Dockerfile)

TASK [agama : Build agama image] ***********************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [agama : Get container info] **********************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [agama : Start agama containers] ******************************************
ok: [1nnu-1] => (item=None)
ok: [1nnu-2] => (item=None)
ok: [1nnu-1] => (item=None)
ok: [1nnu-1]
ok: [1nnu-2] => (item=None)
ok: [1nnu-2]

TASK [agama : Remove unnecessary agama containers] *****************************
skipping: [1nnu-1] => (item={'Id': '84ba0c0da99b45bba961a527554c25f06e51ce45e974ebbe32e54cb5068839e0', 'Image': 'agama', 'Command': 'flask run --host 0.0.0.0 --port 8000', 'Created': 1734256040, 'Status': 'Up 15 minutes', 'Ports': [{'IP': '0.0.0.0', 'PrivatePort': 8000, 'PublicPort': 8002, 'Type': 'tcp'}], 'Names': ['/agama2']}) 
skipping: [1nnu-1] => (item={'Id': '5c1a727156539b0f63a56db33cfa2d110cd23b085af73e79e7299404dd9511e4', 'Image': 'agama', 'Command': 'flask run --host 0.0.0.0 --port 8000', 'Created': 1734256032, 'Status': 'Up 15 minutes', 'Ports': [{'IP': '0.0.0.0', 'PrivatePort': 8000, 'PublicPort': 8001, 'Type': 'tcp'}], 'Names': ['/agama1']}) 
skipping: [1nnu-2] => (item={'Id': '25eb051b826535bade0ef292786ef81584ddf286ad1e8ae7066a69935cd99260', 'Image': 'agama', 'Command': 'flask run --host 0.0.0.0 --port 8000', 'Created': 1734256040, 'Status': 'Up 15 minutes', 'Ports': [{'IP': '0.0.0.0', 'PrivatePort': 8000, 'PublicPort': 8002, 'Type': 'tcp'}], 'Names': ['/agama2']}) 
skipping: [1nnu-2] => (item={'Id': '45fddc529aa9532d805ac731f41e66a8607ccf4782831b78641a0be40e53da10', 'Image': 'agama', 'Command': 'flask run --host 0.0.0.0 --port 8000', 'Created': 1734256032, 'Status': 'Up 15 minutes', 'Ports': [{'IP': '0.0.0.0', 'PrivatePort': 8000, 'PublicPort': 8001, 'Type': 'tcp'}], 'Names': ['/agama1']}) 

TASK [agama : Gather facts for the first dns_primary host] *********************
ok: [1nnu-1 -> 193.40.156.67]
ok: [1nnu-2 -> 193.40.156.67]

TASK [agama : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-1]
ok: [1nnu-2]

TASK [agama : Add agama CNAME records] *****************************************
ok: [1nnu-2]
ok: [1nnu-1]

PLAY RECAP *********************************************************************
1nnu-1                     : ok=76   changed=0    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
1nnu-2                     : ok=76   changed=0    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
1nnu-3                     : ok=73   changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

+ ansible all -b -m reboot -a test_command=uptime
1nnu-3 | CHANGED => {
    "changed": true,
    "elapsed": 38,
    "rebooted": true
}
1nnu-1 | CHANGED => {
    "changed": true,
    "elapsed": 45,
    "rebooted": true
}
1nnu-2 | CHANGED => {
    "changed": true,
    "elapsed": 46,
    "rebooted": true
}
+ sleep 15
+ ansible-playbook infra.yaml --diff
[WARNING]: Collection community.general does not support Ansible version 2.10.8

PLAY [Initial setup] ***********************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-1]
ok: [1nnu-3]
ok: [1nnu-2]

TASK [init : Update APT cache] *************************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [init : Install prometehus-node-exporter from APT] ************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [init : ansible.builtin.service] ******************************************
ok: [1nnu-2]
ok: [1nnu-3]
ok: [1nnu-1]

TASK [init : Install rsyslog] **************************************************
ok: [1nnu-2]
ok: [1nnu-3]
ok: [1nnu-1]

TASK [init : Start and enable rsyslog] *****************************************
ok: [1nnu-2]
ok: [1nnu-3]
ok: [1nnu-1]

TASK [init : Copy rsyslog config] **********************************************
ok: [1nnu-3]
ok: [1nnu-2]
ok: [1nnu-1]

TASK [init : Create backup user with RSA key] **********************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [init : Add backup server public key to known hosts] **********************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [init : Create directory restore dir for backup] **************************
ok: [1nnu-1]
ok: [1nnu-3]
ok: [1nnu-2]

TASK [init : Install duplicity] ************************************************
ok: [1nnu-2]
ok: [1nnu-3]
ok: [1nnu-1]

PLAY [Dns server] **************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-2]
ok: [1nnu-3]
ok: [1nnu-1]

TASK [bind : Install Bind9] ****************************************************
ok: [1nnu-3]
ok: [1nnu-1]
ok: [1nnu-2]

TASK [bind : Install dnspython] ************************************************
ok: [1nnu-1]
ok: [1nnu-2]
ok: [1nnu-3]

TASK [bind : Copy bind config] *************************************************
ok: [1nnu-2] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-1] => (item=None)
ok: [1nnu-2] => (item=None)
ok: [1nnu-2]
ok: [1nnu-3] => (item=None)
ok: [1nnu-3]
ok: [1nnu-1] => (item=None)
ok: [1nnu-1]

TASK [bind : Copy master zone] *************************************************
ok: [1nnu-3] => (item=None)
ok: [1nnu-1] => (item=None)
ok: [1nnu-2] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3]
ok: [1nnu-1] => (item=None)
ok: [1nnu-1]
ok: [1nnu-2] => (item=None)
ok: [1nnu-2]

TASK [bind : Unarchive bind exporter] ******************************************
ok: [1nnu-1]
ok: [1nnu-3]
ok: [1nnu-2]

TASK [bind : link file] ********************************************************
ok: [1nnu-3]
ok: [1nnu-2]
ok: [1nnu-1]

TASK [bind : Copy bind exporter service definition] ****************************
ok: [1nnu-1]
ok: [1nnu-3]
ok: [1nnu-2]

TASK [bind : Reload systemd] ***************************************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [bind : bind service] *****************************************************
ok: [1nnu-1] => (item=bind9)
ok: [1nnu-3] => (item=bind9)
ok: [1nnu-2] => (item=bind9)
ok: [1nnu-1] => (item=prometheus-bind-exporter)
ok: [1nnu-3] => (item=prometheus-bind-exporter)
ok: [1nnu-2] => (item=prometheus-bind-exporter)

TASK [bind : Add backup server A records] **************************************
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1]
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2]
ok: [1nnu-3] => (item=None)
ok: [1nnu-3]

TASK [bind : Add backup server CNAME records] **********************************
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1] => (item=None) 
skipping: [1nnu-1]
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2] => (item=None) 
skipping: [1nnu-2]
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3]

PLAY [Resolv] ******************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-3]
ok: [1nnu-2]
ok: [1nnu-1]

TASK [resolv : Disable systemd-resolved] ***************************************
ok: [1nnu-3]
ok: [1nnu-1]
ok: [1nnu-2]

TASK [resolv : Copy /etc/resolv.conf to hosts] *********************************
ok: [1nnu-1]
ok: [1nnu-3]
ok: [1nnu-2]

PLAY [Docker] ******************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-2]
ok: [1nnu-1]
ok: [1nnu-3]

TASK [docker : Install Docker] *************************************************
ok: [1nnu-3]
ok: [1nnu-2]
ok: [1nnu-1]

TASK [docker : Check docker enabled] *******************************************
ok: [1nnu-3]
ok: [1nnu-2]
ok: [1nnu-1]

TASK [docker : Install python3-docker] *****************************************
ok: [1nnu-3]
ok: [1nnu-2]
ok: [1nnu-1]

PLAY [Prometheus + grafana] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-3]

TASK [prometheus : Install prometheus] *****************************************
ok: [1nnu-3]

TASK [prometheus : Put prometheus args] ****************************************
ok: [1nnu-3]

TASK [prometheus : Configure prometheus] ***************************************
ok: [1nnu-3]

TASK [prometheus : ansible.builtin.service] ************************************
ok: [1nnu-3]

TASK [prometheus : Add prometheus CNAME records] *******************************
ok: [1nnu-3]

TASK [grafana : Grafana directory] *********************************************
ok: [1nnu-3] => (item=/opt/grafana/provisioning/dashboards)
ok: [1nnu-3] => (item=/opt/grafana/provisioning/datasources)

TASK [grafana : Grafana configuration] *****************************************
ok: [1nnu-3]

TASK [grafana : Copy datasource.yml.j2] ****************************************
ok: [1nnu-3]

TASK [grafana : Configure dashboards] ******************************************
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3] => (item=None)
ok: [1nnu-3]

TASK [grafana : Change grafana config] *****************************************
ok: [1nnu-3]

TASK [grafana : Grafana Docker container] **************************************
[DEPRECATION WARNING]: The container_default_behavior option will change its 
default value from "compatibility" to "no_defaults" in community.docker 2.0.0. 
To remove this warning, please specify an explicit value for it now. This 
feature will be removed from community.docker in version 2.0.0. Deprecation 
warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
ok: [1nnu-3]

TASK [grafana : Gather facts for the first dns_primary host] *******************
ok: [1nnu-3 -> 193.40.156.67]

TASK [grafana : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-3]

TASK [grafana : Add grafana CNAME records] *************************************
ok: [1nnu-3]

TASK [nginx : Install nginx from APT] ******************************************
ok: [1nnu-3]

TASK [nginx : nginx configuration] *********************************************
ok: [1nnu-3]

TASK [nginx : nginx service] ***************************************************
ok: [1nnu-3] => (item=nginx)
ok: [1nnu-3] => (item=prometheus-nginx-exporter)

PLAY [InfluxDb] ****************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-3]

TASK [influxdb : add influx gpg key] *******************************************
ok: [1nnu-3]

TASK [influxdb : add influx repo] **********************************************
ok: [1nnu-3]

TASK [influxdb : Install influx] ***********************************************
ok: [1nnu-3]

TASK [influxdb : Copy influxdb config] *****************************************
ok: [1nnu-3]

TASK [influxdb : influxdb started] *********************************************
ok: [1nnu-3]

TASK [influxdb : Install telegraf] *********************************************
ok: [1nnu-3]

TASK [influxdb : Copy telegraf conf] *******************************************
ok: [1nnu-3]

TASK [influxdb : telegraf] *****************************************************
ok: [1nnu-3]

TASK [influxdb : Download Influxdb exporter] ***********************************
ok: [1nnu-3]

TASK [influxdb : Copy influx exporter service file] ****************************
ok: [1nnu-3]

TASK [influxdb : Start and enable influx exporter] *****************************
ok: [1nnu-3]

TASK [influxdb : Create directory for influxdb backup] *************************
ok: [1nnu-3]

TASK [influxdb : Copy cron schedule file] **************************************
ok: [1nnu-3]

TASK [influxdb : Gather facts for the first dns_primary host] ******************
ok: [1nnu-3 -> 193.40.156.67]

TASK [influxdb : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-3]

TASK [influxdb : Add influxdb CNAME records] ***********************************
ok: [1nnu-3]

TASK [agama_client : Add agama-client as system user] **************************
ok: [1nnu-3]

TASK [agama_client : Install fping] ********************************************
ok: [1nnu-3]

TASK [agama_client : copy script to /usr/local/bin/agama-client] ***************
ok: [1nnu-3]

TASK [agama_client : copy service definition to /etc/systemd/system/] **********
ok: [1nnu-3]

TASK [agama_client : Reload systemd] *******************************************
ok: [1nnu-3]

TASK [agama_client : Create directory agama-client app conf dir] ***************
ok: [1nnu-3]

TASK [agama_client : copy conf to to /etc/agama-client/] ***********************
ok: [1nnu-3]

TASK [agama_client : agama-client started] *************************************
ok: [1nnu-3]

PLAY [Database server] *********************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Install mysql-server from APT] ***********************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Mysql configuration] *********************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Install PyMySql from APT] ****************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Check mysql enabled and started] *********************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Create database] *************************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Create agama as database user] ***********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Install mysql exporter] ******************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Create exporter user] ********************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Copy .my.cnf to /var/lib/prometheus/.my.cnf] *********************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Check mysql enabled and started] *********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Check node exporter started] *************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Create directory mysql backup] ***********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Create backup as database user] **********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : Copy .my.cnf to /home/backup/.my.cnf] ****************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Copy cron schedule file] *****************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : MySQL user for replication] **************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [mysql : MySQL read only mode] ********************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [mysql : Add mysql CNAME records] *****************************************
ok: [1nnu-1]
ok: [1nnu-2]

PLAY [Web server] **************************************************************

TASK [Gathering Facts] *********************************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [nginx : Install nginx from APT] ******************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [nginx : nginx configuration] *********************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [nginx : nginx service] ***************************************************
ok: [1nnu-2] => (item=nginx)
ok: [1nnu-1] => (item=nginx)
ok: [1nnu-2] => (item=prometheus-nginx-exporter)
ok: [1nnu-1] => (item=prometheus-nginx-exporter)

TASK [keepalived : Add user "keepalived_script"] *******************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [keepalived : Install keepalived] *****************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Copy keepalived config] *************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Copy keepalived script file] ********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Start and enable keepalived] ********************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [keepalived : Download keepalived exporter] *******************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [keepalived : Copy keepalived exporter service file] **********************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [keepalived : Start and enable keepalived exporter] ***********************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [haproxy : Install HAproxy] ***********************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Copy haproxy conf file] ****************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Start and enable haproxy] **************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Install haproxy exporter] **************************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Copy haproxy exporter conf file] *******************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Start and enable haproxy-exporter] *****************************
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Gather facts for the first dns_primary host] *******************
ok: [1nnu-2 -> 193.40.156.67]
ok: [1nnu-1 -> 193.40.156.67]

TASK [haproxy : Set server_ip variable to the IP of the first dns_primary host] ***
ok: [1nnu-1]
ok: [1nnu-2]

TASK [haproxy : Add haproxy CNAME records] *************************************
ok: [1nnu-1 -> 193.40.156.67]
ok: [1nnu-2 -> 193.40.156.67]

TASK [agama : Create directory for agama user] *********************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [agama : Download agama dockerfile] ***************************************
ok: [1nnu-2] => (item=agama.py)
ok: [1nnu-1] => (item=agama.py)
ok: [1nnu-2] => (item=Dockerfile)
ok: [1nnu-1] => (item=Dockerfile)

TASK [agama : Build agama image] ***********************************************
ok: [1nnu-2]
ok: [1nnu-1]

TASK [agama : Get container info] **********************************************
ok: [1nnu-1]
[WARNING]: sftp transfer mechanism failed on [193.40.156.67]. Use
ANSIBLE_DEBUG=1 to see detailed information
[WARNING]: scp transfer mechanism failed on [193.40.156.67]. Use
ANSIBLE_DEBUG=1 to see detailed information
fatal: [1nnu-2]: FAILED! => {"msg": "Failed to connect to the host via ssh: ssh: connect to host 193.40.156.67 port 13822: Connection timed out"}

TASK [agama : Start agama containers] ******************************************
failed: [1nnu-1] (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result"}
failed: [1nnu-1] (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result"}
fatal: [1nnu-1]: UNREACHABLE! => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}

PLAY RECAP *********************************************************************
1nnu-1                     : ok=72   changed=0    unreachable=1    failed=0    skipped=2    rescued=0    ignored=0   
1nnu-2                     : ok=71   changed=0    unreachable=0    failed=1    skipped=2    rescued=0    ignored=0   
1nnu-3                     : ok=73   changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

